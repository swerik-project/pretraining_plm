{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyriksdagen\n",
    "from lxml import etree\n",
    "import progressbar\n",
    "from pyparlaclarin.read import paragraph_iterator, speeches_with_name,parlaclarin_to_txt,parlaclarin_to_md\n",
    "from pyriksdagen.utils import protocol_iterators, download_corpus\n",
    "from pyriksdagen.metadata import load_Corpus_metadata\n",
    "import pyriksdagen\n",
    "# We need a parser for reading in XML data\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pyparlaclarin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show pyparlaclarin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pyriksdagen.__spec__)\n",
    "download_corpus(partitions=[\"politicians\", \"records\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = list(protocol_iterators(corpus_root=\"data/\", start=1867, end=202122))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(protocols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oppna_data_to_dict(input_dict):\n",
    "    \"\"\"\n",
    "    Load protocols with the new XML / HTML structure (from 2013 onwards)\n",
    "    and convert it to a python dict with contents.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    data[\"paragraphs\"] = []\n",
    "\n",
    "    # Metadata\n",
    "    session = input_dict[\"dokumentstatus\"][\"dokument\"][\"rm\"]\n",
    "    session = session.replace(\"/\", \"\")\n",
    "    pid = input_dict[\"dokumentstatus\"][\"dokument\"][\"nummer\"]\n",
    "    date = input_dict[\"dokumentstatus\"][\"dokument\"][\"datum\"]\n",
    "    html = input_dict[\"dokumentstatus\"][\"dokument\"][\"html\"]\n",
    "    html_tree = clean_html(html)\n",
    "    year = int(date.split(\"-\")[0])\n",
    "    protocol_id = f\"prot-{session}--{pid}\"\n",
    "\n",
    "    data[\"protocol_id\"] = protocol_id\n",
    "    data[\"date\"] = date.split(\" \")[0]\n",
    "    data[\"session\"] = session\n",
    "\n",
    "    # New HTML structure with div[@class='Section1']\n",
    "    section1 = html_tree.xpath(\".//div[@class='Section1']\")\n",
    "    for elements in section1:\n",
    "        for elem in elements:\n",
    "            if elem.tag in [\"p\", \"h1\", \"h2\"]:\n",
    "                elemtext = \"\".join(elem.itertext())\n",
    "                linebreak = elemtext.strip() == \"\" and \"\\n\" in elemtext\n",
    "                if linebreak:\n",
    "                    pass\n",
    "                else:\n",
    "                    paragraph = elemtext.strip()\n",
    "                    paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                    paragraph = re.sub(\"\\\\s+\", \" \", paragraph)\n",
    "                    data[\"paragraphs\"].append(paragraph)\n",
    "\n",
    "    if len(data[\"paragraphs\"]) == 0:\n",
    "        tree = html_tree\n",
    "\n",
    "        # Old data structure 1990-2003\n",
    "        pres = tree.findall(\".//pre\")\n",
    "        if len(pres) > 0:\n",
    "            for pre in pres:\n",
    "                if pre.text is not None:\n",
    "                    tblocks = re.sub(\"([a-zß-ÿ,])- ?\\n ?([a-zß-ÿ])\", \"\\\\1\\\\2\", pre.text)\n",
    "                    tblocks = re.sub(\"([a-zß-ÿ,]) ?\\n ?([a-zß-ÿ])\", \"\\\\1 \\\\2\", tblocks)\n",
    "                    for paragraph in tblocks.split(\"\\n\"):\n",
    "                        paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                        paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                        data[\"paragraphs\"].append(paragraph)\n",
    "\n",
    "        # Standard HTML structure, roughly 2003-2013\n",
    "        elif len(tree.xpath(\"//div[@class='indrag']\")) > 0:\n",
    "            tree = tree.xpath(\"//body\")[0]\n",
    "            for elem in tree:\n",
    "                elemtext = \"\".join(elem.itertext())\n",
    "                linebreak = elemtext.strip() == \"\" and \"\\n\" in elemtext\n",
    "                if elem.tag == \"br\" or linebreak:\n",
    "                    pass\n",
    "                else:\n",
    "                    paragraph = elemtext.strip()\n",
    "                    paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                    paragraph = re.sub(\"\\\\s+\", \" \", paragraph)\n",
    "                    data[\"paragraphs\"].append(paragraph)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_in_question = protocols[10]\n",
    "root = etree.parse(protocol_in_question, parser).getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_in_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for elem in list(paragraph_iterator(root, output=\"lxml\"))[:7]:\n",
    "  print(\" \".join(elem.itertext()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=[]\n",
    "data_test=[]\n",
    "data_valid=[]\n",
    "\n",
    "for i in range(len(protocols)):\n",
    "  protocol_in_question = protocols[i]\n",
    "\n",
    "  h=hash(protocol_in_question)\n",
    "  h_adjusted = h % (2**32 - 1)\n",
    "  np.random.seed(h_adjusted)\n",
    "  r = np.random.rand()\n",
    "  root = etree.parse(protocol_in_question, parser).getroot()\n",
    "  element_str=paragraph_iterator(root, output=\"str\")\n",
    "  if r<=0.7:\n",
    "    data_train.append({\"protocole\": protocol_in_question,\"texte\": \" \".join(element_str)})\n",
    "  elif r<=0.85:\n",
    "    data_test.append({\"protocole\": protocol_in_question,\"texte\": \" \".join(element_str)})\n",
    "  else :\n",
    "    data_valid.append({\"protocole\": protocol_in_question,\"texte\": \" \".join(element_str)})\n",
    "\n",
    "df_train=pd.DataFrame(data_train)\n",
    "df_test=pd.DataFrame(data_test)\n",
    "df_valid=pd.DataFrame(data_valid)\n",
    "\n",
    "print(df_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0][\"texte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"swerick_data_long.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "swerick_dataset = load_dataset(\"pandas\",data_files=\"swerick_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swerick_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_valid(df):\n",
    "    df_train=pd.DataFrame()\n",
    "    df_test=pd.DataFrame(\n",
    "    )\n",
    "    df_valid=pd.DataFrame()\n",
    "\n",
    "    for s in df[\"protocole\"].unique():\n",
    "        subset_df = df[df[\"protocole\"] == s]\n",
    "        h=hash(s)\n",
    "        h_adjusted = h % (2**32 - 1)\n",
    "        np.random.seed(h_adjusted)\n",
    "        r = np.random.rand()\n",
    "        if r <= 0.7 :\n",
    "            df_train = pd.concat([df_train, subset_df], ignore_index=True)\n",
    "        elif r <=0.85:\n",
    "            df_test = pd.concat([df_test, subset_df], ignore_index=True)\n",
    "        else:\n",
    "            df_valid = pd.concat([df_valid, subset_df], ignore_index=True)\n",
    "    return df_train,df_test,df_valid\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test,df_valid=train_test_valid(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train,df_test = train_test_split(df,test_size=0.2,random_state=42)\n",
    "df_train.to_pickle(\"swerick_data_random_train.pkl\")\n",
    "df_test.to_pickle(\"swerick_data_random_test.pkl\")\n",
    "df_valid.to_pickle(\"swerick_data_random_valid.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasest\n",
    "data_files = {\"train\": \"swerick_data_train.pkl\", \"test\": \"swerick_data_test.pkl\"}\n",
    "swerick_dataset = load_dataset(\"pandas\",data_files=data_files)\n",
    "print(swerick_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_in_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "notes=[]\n",
    "intros=[]\n",
    "\n",
    "for i in range(len(protocols)):\n",
    "    protocol_in_question = protocols[i]\n",
    "    with open(protocol_in_question,\"r\") as f:\n",
    "        xml_content=f.read()\n",
    "    soup=BeautifulSoup(xml_content,\"xml\")\n",
    "    note_elements=soup.find_all(\"note\")\n",
    "\n",
    "    for note in note_elements:\n",
    "        note_text=note.text.strip()\n",
    "        notes.append(note_text)\n",
    "\n",
    "        next_element=note.get(\"type\")\n",
    "        if next_element == \"speaker\" :\n",
    "            intros.append(True)\n",
    "        else :\n",
    "            intros.append(False)\n",
    " \n",
    "df=pd.DataFrame({\"Note\" :notes, \"Intro\":intros})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_intro,df_test_intro = train_test_split(df,test_size=0.2,random_state=42)\n",
    "df_train_intro.to_pickle(\"swerick_data_intro_train.pkl\")\n",
    "df_test_intro.to_pickle(\"swerick_data_intro_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata =load_Corpus_metadata()\n",
    "print(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata =pd.DataFrame(metadata)\n",
    "metadata=metadata.set_index(\"person_id\")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(metadata.loc[\"i-Ddmtm1uG9esPH37c8XjUXZ\" ,\"party\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes=[]\n",
    "id=[]\n",
    "party=[]\n",
    "gender=[]\n",
    "protocol=[]\n",
    "\n",
    "for i in range(len(protocols)):\n",
    "    protocol_in_question = protocols[i]\n",
    "    with open(protocol_in_question,\"r\") as f:\n",
    "        xml_content=f.read()\n",
    "    soup=BeautifulSoup(xml_content,\"xml\")\n",
    "    note_elements=soup.find_all(\"u\")\n",
    "\n",
    "\n",
    "    for note in note_elements:\n",
    "        note_text = note.text.strip()\n",
    "        note_text = re.sub(r'\\s+',' ',note_text)\n",
    "        note_text = re.sub(r'\\n+',' ',note_text)\n",
    "        next_element = note.get(\"who\")\n",
    "        if next_element != \"unknown\":\n",
    "            id.append(next_element)\n",
    "            notes.append(note_text)\n",
    "\n",
    "            party_value = metadata.loc[next_element, \"party\"]\n",
    "            if isinstance(party_value, pd.Series):\n",
    "                party_values = party_value.dropna()\n",
    "                if not party_values.empty:\n",
    "                    party.append(party_values.iloc[0])\n",
    "                else:\n",
    "                    party.append(np.nan)\n",
    "            else:\n",
    "                party.append(party_value)\n",
    "\n",
    "            gender_value = metadata.loc[next_element, \"gender\"]\n",
    "            if isinstance(gender_value, pd.Series):\n",
    "                gender_values = gender_value.dropna()\n",
    "                if not gender_values.empty:\n",
    "                    gender.append(gender_values.iloc[0])\n",
    "                else:\n",
    "                    gender.append(np.nan)\n",
    "            else:\n",
    "                gender.append(gender_value)\n",
    "\n",
    "            protocol.append(protocol_in_question)\n",
    "\n",
    "df = pd.DataFrame({\"protocol\": protocol, \"Note\": notes, \"id\": id, \"party\": party, \"gender\": gender})\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"gender_party_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"protocol\": \"protocole\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0][\"Note\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test,df_valid=train_test_valid(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[0][\"Note\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle(\"swerick_data_party_train.pkl\")\n",
    "df_test.to_pickle(\"swerick_data_party_test.pkl\")\n",
    "df_valid.to_pickle(\"swerick_data_party_valid.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
