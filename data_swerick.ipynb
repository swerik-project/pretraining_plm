{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyriksdagen in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: SPARQLWrapper in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (2.0.0)\n",
      "Requirement already satisfied: alto-xml in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (0.0.5)\n",
      "Requirement already satisfied: base58 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (2.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (4.12.2)\n",
      "Requirement already satisfied: dateparser in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (1.2.0)\n",
      "Requirement already satisfied: importlib_resources in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (6.4.0)\n",
      "Requirement already satisfied: kblab-client in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (0.0.16a0)\n",
      "Requirement already satisfied: lxml in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (4.9.3)\n",
      "Requirement already satisfied: matplotlib in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (3.8.0)\n",
      "Requirement already satisfied: nltk in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (2.1.4)\n",
      "Requirement already satisfied: progressbar2 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (4.4.2)\n",
      "Requirement already satisfied: py-markdown-table in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (0.4.0)\n",
      "Requirement already satisfied: pyparlaclarin in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (0.9.0)\n",
      "Requirement already satisfied: requests in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (2.31.0)\n",
      "Requirement already satisfied: textdistance in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (4.2.1)\n",
      "Requirement already satisfied: tqdm in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (4.65.0)\n",
      "Requirement already satisfied: trainerlog in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (0.3.0)\n",
      "Requirement already satisfied: unidecode in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (1.2.0)\n",
      "Requirement already satisfied: xmlschema in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pyriksdagen) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from alto-xml->pyriksdagen) (4.9.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->pyriksdagen) (2.5)\n",
      "Requirement already satisfied: python-dateutil in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from dateparser->pyriksdagen) (2.8.2)\n",
      "Requirement already satisfied: pytz in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from dateparser->pyriksdagen) (2023.3.post1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from dateparser->pyriksdagen) (2023.10.3)\n",
      "Requirement already satisfied: tzlocal in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from dateparser->pyriksdagen) (2.1)\n",
      "Requirement already satisfied: pyyaml in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from kblab-client->pyriksdagen) (6.0.1)\n",
      "Requirement already satisfied: htfile in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from kblab-client->pyriksdagen) (0.0.1a0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from matplotlib->pyriksdagen) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from matplotlib->pyriksdagen) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from matplotlib->pyriksdagen) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from matplotlib->pyriksdagen) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from matplotlib->pyriksdagen) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from matplotlib->pyriksdagen) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from matplotlib->pyriksdagen) (3.0.9)\n",
      "Requirement already satisfied: click in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from nltk->pyriksdagen) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from nltk->pyriksdagen) (1.2.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from pandas->pyriksdagen) (2023.3)\n",
      "Requirement already satisfied: python-utils>=3.8.1 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from progressbar2->pyriksdagen) (3.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from requests->pyriksdagen) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from requests->pyriksdagen) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from requests->pyriksdagen) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from requests->pyriksdagen) (2024.2.2)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from SPARQLWrapper->pyriksdagen) (7.0.0)\n",
      "Requirement already satisfied: colorlog in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from trainerlog->pyriksdagen) (6.8.2)\n",
      "Requirement already satisfied: elementpath<5.0.0,>=4.4.0 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from xmlschema->pyriksdagen) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from python-dateutil->dateparser->pyriksdagen) (1.16.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /home/laurinemeier/anaconda3/lib/python3.11/site-packages (from rdflib>=6.1.1->SPARQLWrapper->pyriksdagen) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyriksdagen\n",
    "from lxml import etree\n",
    "import progressbar\n",
    "from pyparlaclarin.read import paragraph_iterator, speeches_with_name\n",
    "from pyriksdagen.utils import protocol_iterators, download_corpus\n",
    "import pyriksdagen\n",
    "# We need a parser for reading in XML data\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleSpec(name='pyriksdagen', loader=<_frozen_importlib_external.SourceFileLoader object at 0x7473401ad5d0>, origin='/home/laurinemeier/anaconda3/lib/python3.11/site-packages/pyriksdagen/__init__.py', submodule_search_locations=['/home/laurinemeier/anaconda3/lib/python3.11/site-packages/pyriksdagen'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "politicians.zip: 100%|██████████| 2.20M/2.20M [00:00<00:00, 28.9MiB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m11:11:34 [WARNING] \u001b[37m(pyriksdagen)\u001b[0m: data already exists at the path 'data'. It will be overwritten once the download is finished.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "records.zip: 100%|██████████| 1.60G/1.60G [00:20<00:00, 84.8MiB/s]\n"
     ]
    }
   ],
   "source": [
    "print(pyriksdagen.__spec__)\n",
    "download_corpus(partitions=[\"politicians\", \"records\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = list(protocol_iterators(corpus_root=\"data/\", start=1867, end=202122))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oppna_data_to_dict(input_dict):\n",
    "    \"\"\"\n",
    "    Load protocols with the new XML / HTML structure (from 2013 onwards)\n",
    "    and convert it to a python dict with contents.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    data[\"paragraphs\"] = []\n",
    "\n",
    "    # Metadata\n",
    "    session = input_dict[\"dokumentstatus\"][\"dokument\"][\"rm\"]\n",
    "    session = session.replace(\"/\", \"\")\n",
    "    pid = input_dict[\"dokumentstatus\"][\"dokument\"][\"nummer\"]\n",
    "    date = input_dict[\"dokumentstatus\"][\"dokument\"][\"datum\"]\n",
    "    html = input_dict[\"dokumentstatus\"][\"dokument\"][\"html\"]\n",
    "    html_tree = clean_html(html)\n",
    "    year = int(date.split(\"-\")[0])\n",
    "    protocol_id = f\"prot-{session}--{pid}\"\n",
    "\n",
    "    data[\"protocol_id\"] = protocol_id\n",
    "    data[\"date\"] = date.split(\" \")[0]\n",
    "    data[\"session\"] = session\n",
    "\n",
    "    # New HTML structure with div[@class='Section1']\n",
    "    section1 = html_tree.xpath(\".//div[@class='Section1']\")\n",
    "    for elements in section1:\n",
    "        for elem in elements:\n",
    "            if elem.tag in [\"p\", \"h1\", \"h2\"]:\n",
    "                elemtext = \"\".join(elem.itertext())\n",
    "                linebreak = elemtext.strip() == \"\" and \"\\n\" in elemtext\n",
    "                if linebreak:\n",
    "                    pass\n",
    "                else:\n",
    "                    paragraph = elemtext.strip()\n",
    "                    paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                    paragraph = re.sub(\"\\\\s+\", \" \", paragraph)\n",
    "                    data[\"paragraphs\"].append(paragraph)\n",
    "\n",
    "    if len(data[\"paragraphs\"]) == 0:\n",
    "        tree = html_tree\n",
    "\n",
    "        # Old data structure 1990-2003\n",
    "        pres = tree.findall(\".//pre\")\n",
    "        if len(pres) > 0:\n",
    "            for pre in pres:\n",
    "                if pre.text is not None:\n",
    "                    tblocks = re.sub(\"([a-zß-ÿ,])- ?\\n ?([a-zß-ÿ])\", \"\\\\1\\\\2\", pre.text)\n",
    "                    tblocks = re.sub(\"([a-zß-ÿ,]) ?\\n ?([a-zß-ÿ])\", \"\\\\1 \\\\2\", tblocks)\n",
    "                    for paragraph in tblocks.split(\"\\n\"):\n",
    "                        paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                        paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                        data[\"paragraphs\"].append(paragraph)\n",
    "\n",
    "        # Standard HTML structure, roughly 2003-2013\n",
    "        elif len(tree.xpath(\"//div[@class='indrag']\")) > 0:\n",
    "            tree = tree.xpath(\"//body\")[0]\n",
    "            for elem in tree:\n",
    "                elemtext = \"\".join(elem.itertext())\n",
    "                linebreak = elemtext.strip() == \"\" and \"\\n\" in elemtext\n",
    "                if elem.tag == \"br\" or linebreak:\n",
    "                    pass\n",
    "                else:\n",
    "                    paragraph = elemtext.strip()\n",
    "                    paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                    paragraph = re.sub(\"\\\\s+\", \" \", paragraph)\n",
    "                    data[\"paragraphs\"].append(paragraph)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_in_question = protocols[12]\n",
    "root = etree.parse(protocol_in_question, parser).getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "          RIKSDAGENS Ar PROTOKOLL\n",
      "        \n",
      "\n",
      "          1955 ANDRA KAMMAREN Nr 13\n",
      "        \n",
      "\n",
      "          13—15 april\n",
      "        \n",
      "\n",
      "          Debatter m. m.\n",
      "        \n",
      "\n",
      "          Onsdagen den 13 april Sid.\n",
      "        \n",
      "\n",
      "          Familjerådgivning «... 5 Interpellation av herr Ericsson : i\n",
      "          Näs ang. de minskade perioderna\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for elem in list(paragraph_iterator(root, output=\"lxml\"))[:7]:\n",
    "  print(\" \".join(elem.itertext()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       protocole                                              texte\n",
      "0              0  Sedan,ikraftafRiketsRegeringsform,lagtimaRiksd...\n",
      "1              1  24Den19Januari.Lördagenden19Januari,KL!/,11f.m...\n",
      "2              2  Den21Januari.25mandeaftidenfördessaval,erhålli...\n",
      "3              3  Den22Januari.41Tisdagenden22Januari.Kl.10£m.g1...\n",
      "4              4  Den23Januari.-55Onsdagenden23Januari.Kl.10f.m....\n",
      "...          ...                                                ...\n",
      "17637      17637  §1JusteringavprotokollProtokolletförden7juniju...\n",
      "17638      17638  §1JusteringavprotokollProtokolletförden8juniju...\n",
      "17639      17639  §1JusteringavprotokollProtokollenförden9,10,13...\n",
      "17640      17640  §1AnmälanomåtertagandeavplatsiriksdagenTalmann...\n",
      "17641      17641  §1AnmälanomsubsidiaritetsprövningarTalmannenan...\n",
      "\n",
      "[17642 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "\n",
    "for i in range(len(protocols)):\n",
    "  protocol_in_question = protocols[i]\n",
    "  root = etree.parse(protocol_in_question, parser).getroot()\n",
    "  element_str=\"\"\n",
    "  for elem in list(paragraph_iterator(root, output=\"lxml\")):\n",
    "    element_str += \" \".join(elem.itertext()).replace(\"\\n\",\"\")\n",
    "    \n",
    "  data.append({\"protocole\": i,\"texte\": \"\".join(element_str.split())})\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"swerick_data_long.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ddaac0b4e94c489e42a3392a2fa6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "swerick_dataset = load_dataset(\"pandas\",data_files=\"swerick_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['protocole', 'texte'],\n",
      "        num_rows: 130\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(swerick_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(df,test_size=0.2,random_state=42)\n",
    "df_train.to_pickle(\"swerick_data_long_train.pkl\")\n",
    "df_test.to_pickle(\"swerick_data_long_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['protocole', 'texte', '__index_level_0__'],\n",
      "        num_rows: 104\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['protocole', 'texte', '__index_level_0__'],\n",
      "        num_rows: 26\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#datasest\n",
    "data_files = {\"train\": \"swerick_data_train.pkl\", \"test\": \"swerick_data_test.pkl\"}\n",
    "swerick_dataset = load_dataset(\"pandas\",data_files=data_files)\n",
    "print(swerick_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/1867/prot-1867--ak--0202.xml'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protocol_in_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      Note  Intro\n",
      "0        Sedan, i kraft af Rikets Regeringsform, lagtim...  False\n",
      "1           Fredagen den 18 Januari 1867, kl. '/, 11 f. m.  False\n",
      "2        Riksdagens Andra Kammare uti den för dess samm...  False\n",
      "3                                             Mine Herrar!  False\n",
      "4        Enligt 33 8 i Riksdags-ordningen skall, innan ...  False\n",
      "...                                                    ...    ...\n",
      "7027171  § 7 Bordläggning och beslut om förlängd motion...  False\n",
      "7027172          § 8 Anmälan om frågor för skriftliga svar  False\n",
      "7027173           § 9 Anmälan om skriftliga svar på frågor  False\n",
      "7027174  § 10 Anmälan om uteblivna svar på skriftliga f...  False\n",
      "7027175                 § 11 Kammaren åtskildes kl. 11.40.  False\n",
      "\n",
      "[7027176 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "notes=[]\n",
    "intros=[]\n",
    "\n",
    "for i in range(len(protocols)):\n",
    "    protocol_in_question = protocols[i]\n",
    "    with open(protocol_in_question,\"r\") as f:\n",
    "        xml_content=f.read()\n",
    "    soup=BeautifulSoup(xml_content,\"xml\")\n",
    "    note_elements=soup.find_all(\"note\")\n",
    "\n",
    "    for note in note_elements:\n",
    "        note_text=note.text.strip()\n",
    "        notes.append(note_text)\n",
    "\n",
    "        next_element=note.get(\"type\")\n",
    "        if next_element == \"speaker\" :\n",
    "            intros.append(True)\n",
    "        else :\n",
    "            intros.append(False)\n",
    " \n",
    "df=pd.DataFrame({\"Note\" :notes, \"Intro\":intros})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_intro,df_test_intro = train_test_split(df,test_size=0.2,random_state=42)\n",
    "df_train_intro.to_pickle(\"swerick_data_intro_train.pkl\")\n",
    "df_test_intro.to_pickle(\"swerick_data_intro_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
