{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "from torch.optim import AdamW\n",
    "from accelerate import Accelerator\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from data_swerick import create_dataset_swerick\n",
    "from evaluation import evaluation_task,regression_year\n",
    "import preprocessing\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_random_mask(batch,data_collator):\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    masked_inputs = data_collator(features)\n",
    "    # Create a new \"masked\" column for each column in the dataset\n",
    "    return {\"masked_\" + k: v.numpy() for k, v in masked_inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"KBLab/bert-base-swedish-cased\"\n",
    "model = preprocessing.create_model_MLM(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =preprocessing.create_tokenizer(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=pd.read_pickle(\"swerick_data_random_train.pkl\")\n",
    "dataset2=pd.read_pickle(\"swerick_data_random_valid.pkl\")\n",
    "print(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasest\n",
    "data_files = {\"train\": \"swerick_data_random_train.pkl\", \"test\": \"swerick_data_random_test.pkl\"}\n",
    "swerick_dataset = load_dataset(\"pandas\",data_files=data_files)\n",
    "print(swerick_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets =preprocessing.tokenize_dataset(swerick_dataset,tokenizer)\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"token_dataset.pkl\",\"wb\") as f:\n",
    "    pickle.dump(tokenized_datasets,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets=tokenized_datasets.remove_columns(\"protocole\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = preprocessing.grouping_dataset(tokenized_datasets,chunk_size)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lm_dataset.pkl\",\"wb\") as f:\n",
    "    pickle.dump(lm_datasets,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lm_dataset.pkl\",\"rb\") as f:\n",
    "    lm_datasets= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid={\"valid\":\"swerick_data_random_valid.pkl\"}\n",
    "valid_dataset = load_dataset(\"pandas\",data_files=data_valid) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset =preprocessing.tokenize_dataset(valid_dataset,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset=preprocessing.grouping_dataset(valid_dataset,chunk_size)\n",
    "\n",
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"valid_dataset.pkl\",\"wb\") as f:\n",
    "     pickle.dump(valid_dataset,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"valid_dataset.pkl\",\"rb\") as f:\n",
    "    valid_dataset= pickle.load(f)\n",
    "\n",
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_dataset=valid_dataset.remove_columns([\"word_ids\",\"token_type_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = preprocessing.data_collector_masking(tokenizer,0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trial with a manual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm_datasets[\"train\"])\n",
    "\n",
    "lm_dataset_bis = lm_datasets.remove_columns([\"word_ids\",\"token_type_ids\"])\n",
    "\n",
    "print(lm_dataset_bis[\"test\"])\n",
    "eval_dataset = preprocessing.create_deterministic_eval_dataset(lm_dataset_bis[\"test\"],data_collator)\n",
    "valid_dataset=preprocessing.create_deterministic_eval_dataset(valid_dataset[\"valid\"],data_collator)\n",
    "\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = preprocessing.create_dataloader(lm_dataset_bis[\"train\"],batch_size,data_collator)\n",
    "def to_device(batch):\n",
    "    return {key: value.to(\"cpu\") for key, value in batch.items()}\n",
    "\n",
    "print(\"ok\")\n",
    "eval_dataloader = preprocessing.create_dataloader(eval_dataset,batch_size,default_data_collator)\n",
    "valid_dataloader=preprocessing.create_dataloader(valid_dataset,batch_size,default_data_collator)\n",
    "print(\"ok\")\n",
    "\n",
    "#for batch in train_dataloader:\n",
    "    #batch = to_device(batch)\n",
    "\n",
    "#for batch in eval_dataloader:\n",
    "    #batch = to_device(batch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(eval_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataloader.dataset)\n",
    "print(eval_dataloader)\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    print(batch[\"input_ids\"].device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader():\n",
    "    train =DataLoader(\n",
    "    lm_dataset_bis[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator)\n",
    "    train = [inputs.to(device) for inputs in train_dataloader]\n",
    "    return train\n",
    "\n",
    "\n",
    "for step,batch in enumerate(get_dataloader()):\n",
    "    print(\n",
    "        tokenizer.decode(batch[\"input_ids\"][0]))\n",
    "    break\n",
    "\n",
    "for step,batch in enumerate(get_dataloader()):\n",
    "    print(\n",
    "        tokenizer.decode(batch[\"input_ids\"][0]))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bis = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "model_bis=model_bis.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bis.eval()\n",
    "\n",
    "total_loss = 0.0  # Variable to accumulate total loss\n",
    "\n",
    "for step, batch in enumerate(eval_dataloader):\n",
    "    with torch.no_grad():\n",
    "        outputs = model_bis(**batch)\n",
    "    loss = outputs.loss\n",
    "    total_loss += loss.item()   # Accumulate the batch loss\n",
    "\n",
    "# Calculate the average loss\n",
    "average_loss = total_loss / len(eval_dataloader)\n",
    "\n",
    "print(f\"Initial Loss: {average_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = AdamW(model_bis.parameters(), lr=1.3e-5)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "losses_train=[]\n",
    "losses_test=[]\n",
    "#train_dataloader = get_dataloader()\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model_bis.train()\n",
    "    print(next(model_bis.parameters()).device)\n",
    "    print(epoch)\n",
    "    params_before_optimization = [param.data.clone() for param in model_bis.parameters()]\n",
    "    total_loss_train = 0.0 \n",
    "    train_dataloader = get_dataloader()\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model_bis(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss_train += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        params_after_optimization = [param.data for param in model_bis.parameters()]\n",
    "        parameters_changed = any((param_before != param_after).any() for param_before, param_after in zip(params_before_optimization, params_after_optimization))\n",
    "        #if parameters_changed==True :\n",
    "             # print(parameters_changed) \n",
    "        progress_bar.update(1)\n",
    "\n",
    "    losses_train.append(total_loss_train/len(train_dataloader))\n",
    "    print(\"losses_train\",losses_train)\n",
    "\n",
    "    # Evaluation\n",
    "    model_bis.eval()\n",
    "    losses=[]\n",
    "    total_loss_eval=0.0\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bis(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        losses.append(loss.repeat(batch_size))\n",
    "        total_loss_eval +=loss.item()\n",
    "\n",
    "\n",
    "    losses = torch.cat(losses)\n",
    "    losses = losses[: len(eval_dataset)]\n",
    "    try:\n",
    "        perplexity = math.exp(torch.mean(losses))\n",
    "    except OverflowError:\n",
    "       perplexity = float(\"inf\")\n",
    "\n",
    "    losses_test.append(total_loss_eval/len(eval_dataloader))\n",
    "\n",
    "\n",
    "    print(f\">>> Epoch {epoch}: Perplexity: {perplexity}\")\n",
    "\n",
    "    print(\"losses_test\",losses_test)\n",
    "\n",
    "print(\"epoch\",num_train_epochs)\n",
    "plt.plot(range(num_train_epochs),losses_train,label=\"train Loss\")\n",
    "\n",
    "plt.plot(range(num_train_epochs),losses_test,label=\"test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(losses_train)\n",
    "print(losses_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"finetuning_manual\"\n",
    "model_bis.save_pretrained(file_path)\n",
    "tokenizer.save_pretrained(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_name = \"losses.pkl\"\n",
    "\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump({'losses_train': losses_train, 'losses_test': losses_test}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(task=\"fill-mask\", model=\"./test_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_long=AutoModelForMaskedLM.from_pretrained(\"./finetuning_hugging-finetuned-imdb/checkpoint-259384\")\n",
    "model_long=model_long.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AutoModelForMaskedLM.from_pretrained(\"./test_model\")\n",
    "model=model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hugging_face = AutoModelForMaskedLM.from_pretrained(\"finetuning_hugging_whitespace-finetuned-imdb/checkpoint-4179250\")\n",
    "model_hugging_face=model_hugging_face.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kb=AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "model_kb=model_kb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_task(model_hugging_face,valid_dataloader,\"finetuning_hugging_whitespace-finetuned-imdb/checkpoint-4179250\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_task(model,valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in eval_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(0.13192342221736908)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Charger les données à partir du fichier JSON\n",
    "with open(\"finetuning_hugging_whitespace-finetuned-imdb/checkpoint-4179250/trainer_state.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "epoch_train = []\n",
    "epoch_test=[]\n",
    "\n",
    "for entry in data['log_history']:\n",
    "    if 'loss' in entry:\n",
    "        train_loss.append(entry['loss'])\n",
    "        epoch_train.append((entry['epoch']))\n",
    "    elif 'eval_loss' in entry:\n",
    "        eval_loss.append(entry['eval_loss'])\n",
    "        epoch_test.append((entry['epoch']))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epoch_train, train_loss, label='Training Loss', marker='o')\n",
    "plt.plot(epoch_test, eval_loss, label='Evaluation Loss', marker='o')\n",
    "plt.title('Training and Evaluation Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_id= tokenizer.pad_token_id\n",
    "sep_token_id = tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_special_masking(batch,i):\n",
    "    word_ids=batch[\"word_ids\"]\n",
    " \n",
    "    masked_input_id=batch[\"input_ids\"].copy()\n",
    "    attention_mask=batch[\"attention_mask\"].copy()\n",
    " \n",
    "    labels=[[-100]*max_length]*len(batch[\"labels\"])\n",
    "    for z in range(len(masked_input_id)):\n",
    "        if batch[\"input_ids\"][z][i] ==tokenizer.pad_token_id or batch[\"input_ids\"][z][i] ==tokenizer.sep_token_id:\n",
    "            continue\n",
    "        \n",
    "        labels[z][i]=batch[\"input_ids\"][z][i]\n",
    "        masked_input_id[z][i]=tokenizer.mask_token_id\n",
    "  \n",
    "        \n",
    "        word=tokenizer.decode(batch[\"input_ids\"][z][i])\n",
    "   \n",
    "        future_token=[j for j,_ in enumerate(word_ids[z]) if word_ids[z][j]==word_ids[z][i] and j>i]\n",
    "\n",
    "        for j in future_token:\n",
    "            labels[z][j]=batch[\"input_ids\"][z][j]\n",
    "    \n",
    "            masked_input_id[z][j]=tokenizer.mask_token_id\n",
    "           \n",
    "\n",
    "        masked_input_id[z]=np.array(masked_input_id[z])\n",
    "        attention_mask[z]=np.array(attention_mask[z])\n",
    "        labels[z]=np.array(labels[z])\n",
    "   \n",
    "    output_dict = {\"input_ids\": masked_input_id, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "    \n",
    "    return {k: v for k, v in output_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_special_masking_bis(batch, i):\n",
    "    word_ids = batch[\"word_ids\"]\n",
    "    masked_input_id = batch[\"input_ids\"].copy()\n",
    "    attention_mask = batch[\"attention_mask\"].copy()\n",
    "    \n",
    "    labels = np.full_like(masked_input_id, -100)\n",
    "    \n",
    "    for z, seq in enumerate(masked_input_id):\n",
    "        if seq[i] == tokenizer.pad_token_id or seq[i] == tokenizer.sep_token_id:\n",
    "            continue\n",
    "        \n",
    "        labels[z, i] = seq[i]\n",
    "        masked_input_id[z][i] = tokenizer.mask_token_id\n",
    "        future_token = [j for j, _ in enumerate(word_ids[z]) if word_ids[z][j] == word_ids[z][i] and j > i]\n",
    "        \n",
    "        for j in future_token:\n",
    "            labels[z][j] = batch[\"input_ids\"][z][j]\n",
    "            masked_input_id[z][j] = tokenizer.mask_token_id\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": masked_input_id,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pll = 0\n",
    "batch_size=64\n",
    "for i in  range(max_length):\n",
    "    print(i)\n",
    "    losses=[]\n",
    "    eval_dataset_log = lm_datasets[\"test\"].map(\n",
    "        lambda examples: insert_special_masking_bis(examples,i),\n",
    "        batched=True,\n",
    "        remove_columns= lm_datasets[\"test\"].column_names\n",
    "    )\n",
    "    print(\"daatset\")\n",
    "    eval_dataloader = preprocessing.create_dataloader(eval_dataset_log,batch_size,default_data_collator)\n",
    "    print(\"dataloader\")\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        batch={key: value.to(device) for key, value in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            output=model_hugging_face(**batch)\n",
    "        print(\"output\")\n",
    "        loss=output.loss\n",
    "        losses.append(loss.repeat(eval_dataloader.batch_size))\n",
    "        print(\"loss\")\n",
    "        break\n",
    "    losses = torch.cat(losses)\n",
    "    print(\"loss\")\n",
    "    #losses = losses[: len(eval_dataloader.dataset)]\n",
    "    pll += torch.mean(losses)\n",
    "\n",
    "\n",
    "pll /=max_length\n",
    "pll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_task(model_kb,eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_year(\"finetuning_hugging_whitespace-finetuned-imdb/checkpoint-801500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df, tokenizer):\n",
    "    # Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for ix, row in df.iterrows():\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            row['content'],\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        \n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    print(df[\"tag\"])\n",
    "    labels = torch.tensor(df['tag'].tolist())\n",
    "\n",
    "    return input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"swerick_subsetdata_date_test.csv\")\n",
    "df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "# Create binary label where seg = 1\n",
    "df = df[df[\"content\"].notnull()]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "input_ids, attention_masks, labels = encode(df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define your training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_long.config.name_or_path}-imdb\",\n",
    "    per_device_eval_batch_size=64,\n",
    "    # Add other training arguments as needed\n",
    "    logging_steps=892,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    no_cuda=True\n",
    ")\n",
    "print(training_args.device)\n",
    "# Create the Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model_long,\n",
    "    args=training_args,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "\n",
    "result = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(result['eval_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
