{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyriksdagen in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: SPARQLWrapper in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (2.0.0)\n",
      "Requirement already satisfied: alto-xml in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (0.0.5)\n",
      "Requirement already satisfied: base58 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (2.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (4.12.3)\n",
      "Requirement already satisfied: dateparser in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (1.2.0)\n",
      "Requirement already satisfied: importlib_resources in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (6.4.0)\n",
      "Requirement already satisfied: kblab-client in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (0.0.16a0)\n",
      "Requirement already satisfied: lxml in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (5.2.1)\n",
      "Requirement already satisfied: matplotlib in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (3.8.4)\n",
      "Requirement already satisfied: nltk in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (2.2.1)\n",
      "Requirement already satisfied: progressbar2 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (4.4.2)\n",
      "Requirement already satisfied: py-markdown-table in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (0.4.0)\n",
      "Requirement already satisfied: pyparlaclarin in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (0.9.1)\n",
      "Requirement already satisfied: requests in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (2.31.0)\n",
      "Requirement already satisfied: textdistance in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (4.6.1)\n",
      "Requirement already satisfied: tqdm in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (4.66.2)\n",
      "Requirement already satisfied: trainerlog in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (0.3.0)\n",
      "Requirement already satisfied: unidecode in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (1.3.8)\n",
      "Requirement already satisfied: xmlschema in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pyriksdagen) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from alto-xml->pyriksdagen) (4.9.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from beautifulsoup4->pyriksdagen) (2.5)\n",
      "Requirement already satisfied: python-dateutil in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from dateparser->pyriksdagen) (2.8.2)\n",
      "Requirement already satisfied: pytz in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from dateparser->pyriksdagen) (2023.3.post1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from dateparser->pyriksdagen) (2023.12.25)\n",
      "Requirement already satisfied: tzlocal in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from dateparser->pyriksdagen) (5.2)\n",
      "Requirement already satisfied: pyyaml in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from kblab-client->pyriksdagen) (6.0.1)\n",
      "Requirement already satisfied: htfile in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from kblab-client->pyriksdagen) (0.0.1a0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from matplotlib->pyriksdagen) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from matplotlib->pyriksdagen) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from matplotlib->pyriksdagen) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from matplotlib->pyriksdagen) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from matplotlib->pyriksdagen) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from matplotlib->pyriksdagen) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from matplotlib->pyriksdagen) (3.1.2)\n",
      "Requirement already satisfied: click in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from nltk->pyriksdagen) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from nltk->pyriksdagen) (1.4.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from pandas->pyriksdagen) (2023.3)\n",
      "Requirement already satisfied: python-utils>=3.8.1 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from progressbar2->pyriksdagen) (3.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from requests->pyriksdagen) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from requests->pyriksdagen) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from requests->pyriksdagen) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from requests->pyriksdagen) (2024.2.2)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from SPARQLWrapper->pyriksdagen) (7.0.0)\n",
      "Requirement already satisfied: colorlog in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from trainerlog->pyriksdagen) (6.8.2)\n",
      "Requirement already satisfied: elementpath<5.0.0,>=4.4.0 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from xmlschema->pyriksdagen) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from python-dateutil->dateparser->pyriksdagen) (1.16.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /home/laurinemeier/anaconda3/envs/swerick/lib/python3.12/site-packages (from rdflib>=6.1.1->SPARQLWrapper->pyriksdagen) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyriksdagen\n",
    "from lxml import etree\n",
    "import progressbar\n",
    "from pyparlaclarin.read import paragraph_iterator, speeches_with_name,parlaclarin_to_txt,parlaclarin_to_md\n",
    "from pyriksdagen.utils import protocol_iterators, download_corpus\n",
    "from pyriksdagen.metadata import load_Corpus_metadata\n",
    "import pyriksdagen\n",
    "# We need a parser for reading in XML data\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pyparlaclarin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show pyparlaclarin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pyriksdagen.__spec__)\n",
    "download_corpus(partitions=[\"politicians\", \"records\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = list(protocol_iterators(corpus_root=\"data/\", start=1867, end=202122))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(protocols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oppna_data_to_dict(input_dict):\n",
    "    \"\"\"\n",
    "    Load protocols with the new XML / HTML structure (from 2013 onwards)\n",
    "    and convert it to a python dict with contents.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    data[\"paragraphs\"] = []\n",
    "\n",
    "    # Metadata\n",
    "    session = input_dict[\"dokumentstatus\"][\"dokument\"][\"rm\"]\n",
    "    session = session.replace(\"/\", \"\")\n",
    "    pid = input_dict[\"dokumentstatus\"][\"dokument\"][\"nummer\"]\n",
    "    date = input_dict[\"dokumentstatus\"][\"dokument\"][\"datum\"]\n",
    "    html = input_dict[\"dokumentstatus\"][\"dokument\"][\"html\"]\n",
    "    html_tree = clean_html(html)\n",
    "    year = int(date.split(\"-\")[0])\n",
    "    protocol_id = f\"prot-{session}--{pid}\"\n",
    "\n",
    "    data[\"protocol_id\"] = protocol_id\n",
    "    data[\"date\"] = date.split(\" \")[0]\n",
    "    data[\"session\"] = session\n",
    "\n",
    "    # New HTML structure with div[@class='Section1']\n",
    "    section1 = html_tree.xpath(\".//div[@class='Section1']\")\n",
    "    for elements in section1:\n",
    "        for elem in elements:\n",
    "            if elem.tag in [\"p\", \"h1\", \"h2\"]:\n",
    "                elemtext = \"\".join(elem.itertext())\n",
    "                linebreak = elemtext.strip() == \"\" and \"\\n\" in elemtext\n",
    "                if linebreak:\n",
    "                    pass\n",
    "                else:\n",
    "                    paragraph = elemtext.strip()\n",
    "                    paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                    paragraph = re.sub(\"\\\\s+\", \" \", paragraph)\n",
    "                    data[\"paragraphs\"].append(paragraph)\n",
    "\n",
    "    if len(data[\"paragraphs\"]) == 0:\n",
    "        tree = html_tree\n",
    "\n",
    "        # Old data structure 1990-2003\n",
    "        pres = tree.findall(\".//pre\")\n",
    "        if len(pres) > 0:\n",
    "            for pre in pres:\n",
    "                if pre.text is not None:\n",
    "                    tblocks = re.sub(\"([a-zß-ÿ,])- ?\\n ?([a-zß-ÿ])\", \"\\\\1\\\\2\", pre.text)\n",
    "                    tblocks = re.sub(\"([a-zß-ÿ,]) ?\\n ?([a-zß-ÿ])\", \"\\\\1 \\\\2\", tblocks)\n",
    "                    for paragraph in tblocks.split(\"\\n\"):\n",
    "                        paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                        paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                        data[\"paragraphs\"].append(paragraph)\n",
    "\n",
    "        # Standard HTML structure, roughly 2003-2013\n",
    "        elif len(tree.xpath(\"//div[@class='indrag']\")) > 0:\n",
    "            tree = tree.xpath(\"//body\")[0]\n",
    "            for elem in tree:\n",
    "                elemtext = \"\".join(elem.itertext())\n",
    "                linebreak = elemtext.strip() == \"\" and \"\\n\" in elemtext\n",
    "                if elem.tag == \"br\" or linebreak:\n",
    "                    pass\n",
    "                else:\n",
    "                    paragraph = elemtext.strip()\n",
    "                    paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "                    paragraph = re.sub(\"\\\\s+\", \" \", paragraph)\n",
    "                    data[\"paragraphs\"].append(paragraph)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_in_question = protocols[10]\n",
    "root = etree.parse(protocol_in_question, parser).getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_in_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for elem in list(paragraph_iterator(root, output=\"lxml\"))[:7]:\n",
    "  print(\" \".join(elem.itertext()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=[]\n",
    "data_test=[]\n",
    "data_valid=[]\n",
    "\n",
    "for i in range(len(protocols)):\n",
    "  protocol_in_question = protocols[i]\n",
    "\n",
    "  h=hash(protocol_in_question)\n",
    "  h_adjusted = h % (2**32 - 1)\n",
    "  np.random.seed(h_adjusted)\n",
    "  r = np.random.rand()\n",
    "  root = etree.parse(protocol_in_question, parser).getroot()\n",
    "  element_str=paragraph_iterator(root, output=\"str\")\n",
    "  if r<=0.7:\n",
    "    data_train.append({\"protocole\": protocol_in_question,\"texte\": \" \".join(element_str)})\n",
    "  elif r<=0.85:\n",
    "    data_test.append({\"protocole\": protocol_in_question,\"texte\": \" \".join(element_str)})\n",
    "  else :\n",
    "    data_valid.append({\"protocole\": protocol_in_question,\"texte\": \" \".join(element_str)})\n",
    "\n",
    "df_train=pd.DataFrame(data_train)\n",
    "df_test=pd.DataFrame(data_test)\n",
    "df_valid=pd.DataFrame(data_valid)\n",
    "\n",
    "print(df_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0][\"texte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"swerick_data_long.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "swerick_dataset = load_dataset(\"pandas\",data_files=\"swerick_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swerick_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_valid(df):\n",
    "    df_train=pd.DataFrame()\n",
    "    df_test=pd.DataFrame(\n",
    "    )\n",
    "    df_valid=pd.DataFrame()\n",
    "\n",
    "    for s in df[\"protocole\"].unique():\n",
    "        subset_df = df[df[\"protocole\"] == s]\n",
    "        h=hash(s)\n",
    "        h_adjusted = h % (2**32 - 1)\n",
    "        np.random.seed(h_adjusted)\n",
    "        r = np.random.rand()\n",
    "        if r <= 0.7 :\n",
    "            df_train = pd.concat([df_train, subset_df], ignore_index=True)\n",
    "        elif r <=0.85:\n",
    "            df_test = pd.concat([df_test, subset_df], ignore_index=True)\n",
    "        else:\n",
    "            df_valid = pd.concat([df_valid, subset_df], ignore_index=True)\n",
    "    return df_train,df_test,df_valid\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test,df_valid=train_test_valid(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train,df_test = train_test_split(df,test_size=0.2,random_state=42)\n",
    "df_train.to_pickle(\"swerick_data_random_train.pkl\")\n",
    "df_test.to_pickle(\"swerick_data_random_test.pkl\")\n",
    "df_valid.to_pickle(\"swerick_data_random_valid.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasest\n",
    "data_files = {\"train\": \"swerick_data_train.pkl\", \"test\": \"swerick_data_test.pkl\"}\n",
    "swerick_dataset = load_dataset(\"pandas\",data_files=data_files)\n",
    "print(swerick_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_in_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "notes=[]\n",
    "intros=[]\n",
    "\n",
    "for i in range(len(protocols)):\n",
    "    protocol_in_question = protocols[i]\n",
    "    with open(protocol_in_question,\"r\") as f:\n",
    "        xml_content=f.read()\n",
    "    soup=BeautifulSoup(xml_content,\"xml\")\n",
    "    note_elements=soup.find_all(\"note\")\n",
    "\n",
    "    for note in note_elements:\n",
    "        note_text=note.text.strip()\n",
    "        notes.append(note_text)\n",
    "\n",
    "        next_element=note.get(\"type\")\n",
    "        if next_element == \"speaker\" :\n",
    "            intros.append(True)\n",
    "        else :\n",
    "            intros.append(False)\n",
    " \n",
    "df=pd.DataFrame({\"Note\" :notes, \"Intro\":intros})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_intro,df_test_intro = train_test_split(df,test_size=0.2,random_state=42)\n",
    "df_train_intro.to_pickle(\"swerick_data_intro_train.pkl\")\n",
    "df_test_intro.to_pickle(\"swerick_data_intro_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata =load_Corpus_metadata()\n",
    "print(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata =pd.DataFrame(metadata)\n",
    "metadata=metadata.set_index(\"person_id\")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(metadata.loc[\"i-Ddmtm1uG9esPH37c8XjUXZ\" ,\"party\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes=[]\n",
    "id=[]\n",
    "party=[]\n",
    "gender=[]\n",
    "protocol=[]\n",
    "\n",
    "for i in range(len(protocols)):\n",
    "    protocol_in_question = protocols[i]\n",
    "    with open(protocol_in_question,\"r\") as f:\n",
    "        xml_content=f.read()\n",
    "    soup=BeautifulSoup(xml_content,\"xml\")\n",
    "    note_elements=soup.find_all(\"u\")\n",
    "\n",
    "\n",
    "    for note in note_elements:\n",
    "        note_text = note.text.strip()\n",
    "        note_text = re.sub(r'\\s+',' ',note_text)\n",
    "        note_text = re.sub(r'\\n+',' ',note_text)\n",
    "        next_element = note.get(\"who\")\n",
    "        if next_element != \"unknown\":\n",
    "            id.append(next_element)\n",
    "            notes.append(note_text)\n",
    "\n",
    "            party_value = metadata.loc[next_element, \"party\"]\n",
    "            if isinstance(party_value, pd.Series):\n",
    "                party_values = party_value.dropna()\n",
    "                if not party_values.empty:\n",
    "                    party.append(party_values.iloc[0])\n",
    "                else:\n",
    "                    party.append(np.nan)\n",
    "            else:\n",
    "                party.append(party_value)\n",
    "\n",
    "            gender_value = metadata.loc[next_element, \"gender\"]\n",
    "            if isinstance(gender_value, pd.Series):\n",
    "                gender_values = gender_value.dropna()\n",
    "                if not gender_values.empty:\n",
    "                    gender.append(gender_values.iloc[0])\n",
    "                else:\n",
    "                    gender.append(np.nan)\n",
    "            else:\n",
    "                gender.append(gender_value)\n",
    "\n",
    "            protocol.append(protocol_in_question)\n",
    "\n",
    "df = pd.DataFrame({\"protocol\": protocol, \"Note\": notes, \"id\": id, \"party\": party, \"gender\": gender})\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       Text Note/seg\n",
      "0         Sedan, i kraft af Rikets Regeringsform, lagtim...     note\n",
      "1            Fredagen den 18 Januari 1867, kl. '/, 11 f. m.     note\n",
      "2         Riksdagens Andra Kammare uti den för dess samm...     note\n",
      "3                                              Mine Herrar!     note\n",
      "4         Enligt 33 8 i Riksdags-ordningen skall, innan ...     note\n",
      "...                                                     ...      ...\n",
      "14108231  2021/22:1889 Sveriges arbete för kärnvapennedr...      seg\n",
      "14108232  till näringsminister Karl-Petter Thorwaldsson (S)      seg\n",
      "14108233  2021/22:1909 Växande skulder till följd av hög...      seg\n",
      "14108234                                        GERGÖ KISCH      seg\n",
      "14108235         Tryck: Elanders Sverige AB, Vällingby 2022      seg\n",
      "\n",
      "[14108236 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#NOte Seg classification\n",
    "\n",
    "\n",
    "\n",
    "text=[]\n",
    "note_seg=[]\n",
    "\n",
    "for i in range(len(protocols)):\n",
    "    protocol_in_question = protocols[i]\n",
    "    with open(protocol_in_question,\"r\") as f:\n",
    "        xml_content=f.read()\n",
    "    soup=BeautifulSoup(xml_content,\"xml\")\n",
    "    note_elements=soup.find_all(\"note\")\n",
    "    seg_elements=soup.find_all(\"seg\")\n",
    "\n",
    "    for note in note_elements:\n",
    "        text.append(note.text.strip())\n",
    "        note_seg.append(\"note\")\n",
    "\n",
    "    for seg in seg_elements:\n",
    "        text.append(seg.text.strip())\n",
    "        note_seg.append(\"seg\")\n",
    "\n",
    "df=pd.DataFrame({\"Text\" :text, \"Note/seg\":note_seg})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_seg,df_test_seg = train_test_split(df,test_size=0.2,random_state=42)\n",
    "df_train_seg.to_pickle(\"swerick_data_seg_train.pkl\")\n",
    "df_test_seg.to_pickle(\"swerick_data_seg_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"gender_party_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"protocol\": \"protocole\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0][\"Note\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test,df_valid=train_test_valid(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[0][\"Note\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle(\"swerick_data_party_train.pkl\")\n",
    "df_test.to_pickle(\"swerick_data_party_test.pkl\")\n",
    "df_valid.to_pickle(\"swerick_data_party_valid.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
