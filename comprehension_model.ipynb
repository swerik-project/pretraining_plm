{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from collections import Counter\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "from torch.optim import AdamW\n",
    "from accelerate import Accelerator\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import comprehension_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['protocole', 'texte'],\n",
      "        num_rows: 12399\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['protocole', 'texte'],\n",
      "        num_rows: 2673\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_files = {\"train\": \"swerick_data_random_train.pkl\", \"test\": \"swerick_data_random_test.pkl\"}\n",
    "swerick_dataset = load_dataset(\"pandas\",data_files=data_files)\n",
    "print(swerick_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"KBLab/bert-base-swedish-cased\"\n",
    "tokenizer =preprocessing.create_tokenizer(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at KBLab/bert-base-swedish-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_kb = preprocessing.create_model_MLM(model_checkpoint)\n",
    "model_kb=model_kb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =preprocessing.create_tokenizer(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exbert_tokenizer = AutoTokenizer.from_pretrained(\"exbert_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "swerick_tokenizer= PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"/home/laurinemeier/swerick/alvis_project/pretraining_from_scratch/tokenizer_swerick.json\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lm_dataset.pkl\",\"rb\") as f:\n",
    "    lm_datasets= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"valid_dataset.pkl\",\"rb\") as f:\n",
    "    valid_dataset= pickle.load(f)\n",
    "\n",
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset=valid_dataset.remove_columns([\"word_ids\"])\n",
    "data_collator = preprocessing.data_collector_masking(tokenizer,0.15)\n",
    "lm_dataset_bis = lm_datasets.remove_columns([\"word_ids\",\"token_type_ids\"])\n",
    "\n",
    "print(lm_dataset_bis[\"test\"])\n",
    "eval_dataset = preprocessing.create_deterministic_eval_dataset(lm_dataset_bis[\"test\"],data_collator)\n",
    "valid_dataset=preprocessing.create_deterministic_eval_dataset(valid_dataset,data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "valid_dataset=valid_dataset.remove_columns([\"word_ids\"])\n",
    "data_collator = preprocessing.data_collector_masking(tokenizer,0.15)\n",
    "small_valid_dataset = preprocessing.create_deterministic_eval_dataset(valid_dataset.select(range(10000)),data_collator)\n",
    "small_valid_dataloader=preprocessing.create_dataloader(small_valid_dataset,64,default_data_collator)\n",
    "                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"Statsr√•det\"\n",
    "token_id = tokenizer.convert_tokens_to_ids(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_token(token,example):\n",
    "    return token in example['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_filtered_dataset = valid_dataset.filter(lambda example : special_token(token_id,example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_filtered_dataloader=preprocessing.create_dataloader(valid_filtered_dataset,64,default_data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = preprocessing.create_dataloader(lm_dataset_bis[\"train\"],batch_size,data_collator)\n",
    "def to_device(batch):\n",
    "    return {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "print(\"ok\")\n",
    "eval_dataloader = preprocessing.create_dataloader(eval_dataset,batch_size,default_data_collator)\n",
    "valid_dataloader=preprocessing.create_dataloader(valid_dataset,batch_size,default_data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hugging_face = AutoModelForMaskedLM.from_pretrained(\"finetuning_hugging_whitespace_bis-finetuned-imdb/checkpoint-2175500\")\n",
    "model_hugging_face=model_hugging_face.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exbert = AutoModelForMaskedLM.from_pretrained(\"exbert-finetuned-imdb/checkpoint-3995640\")\n",
    "model_exbert=model_exbert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "config = transformers.BertConfig.from_pretrained(\"alvis_project/pretraining_from_scratch/checkpoint-5258900\")\n",
    "mosaicBert = AutoModelForMaskedLM.from_pretrained(\"alvis_project/pretraining_from_scratch/checkpoint-5258900\",config=config,trust_remote_code=True)\n",
    "mosaicBert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "valid_sentence_filtered = valid_filtered_dataset.map(lambda example : preprocessing.get_context_with_mask(example,token_id,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_bis(model,dataloader, tokenizer,token_id):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    layerwise_embeddings = [[] for _ in range(model.config.num_hidden_layers + 1)]\n",
    "    preds=[]\n",
    "    for batch in dataloader :\n",
    "        tokens={key : value.to(device) for key,value in batch.items()}\n",
    "        if token_id not in list(batch[\"labels\"][0]):\n",
    "            continue\n",
    "        index=list(batch[\"labels\"][0]).index(token_id)\n",
    "        outputs= model(input_ids=tokens[\"input_ids\"],attention_mask=tokens[\"attention_mask\"],labels=tokens[\"labels\"],output_hidden_states=True)\n",
    "        preds.append(torch.argmax(F.softmax(outputs.logits.squeeze(0)[index])))\n",
    "        hidden_states = outputs.hidden_states  # tuple of (layer+1) tensors, each of shape (batch_size, seq_len, hidden_size)\n",
    "        for i, hidden_state in enumerate(hidden_states):\n",
    "            masked_embeddings = hidden_state[:, index, :].detach().cpu().numpy()  # Extract [CLS] token\n",
    "            layerwise_embeddings[i].append(masked_embeddings)\n",
    "    return [np.vstack(layer) for layer in layerwise_embeddings],preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "inputs = valid_sentence_filtered[3]\n",
    "print(tokenizer.decode(inputs[\"input_ids\"]))\n",
    "token = {key: torch.tensor(value, dtype=torch.long).unsqueeze(0).to(device) for key,value in inputs.items()}\n",
    "outputs = model_hugging_face(input_ids=token[\"input_ids\"],attention_mask=token[\"attention_mask\"],labels=token[\"labels\"],output_hidden_states=True)\n",
    "outputs2=model_kb(input_ids=token[\"input_ids\"],attention_mask=token[\"attention_mask\"],labels=token[\"labels\"],output_hidden_states=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(token[\"input_ids\"].squeeze())\n",
    "index=inputs[\"labels\"].index(token_id)\n",
    "hidden_states = outputs.hidden_states\n",
    "hidden_states_kb = outputs2.hidden_states\n",
    "last_hidden_state = hidden_states[-1].squeeze().detach().cpu().numpy()\n",
    "print(tokenizer.decode(torch.argmax(outputs.logits.squeeze()[index])))\n",
    "print(tokenizer.decode(torch.argmax(outputs2.logits.squeeze()[index])))\n",
    "def plot_pca_hidden_state(hidden_state,tokens,number):\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_states = pca.fit_transform(hidden_state.squeeze().detach().cpu().numpy())\n",
    "\n",
    "    # Pr√©parer la figure pour la visualisation\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in [\"[CLS]\",\"[SEP]\"]:\n",
    "            color = 'green'  # Token sp√©cial\n",
    "        elif token == '[MASK]':\n",
    "            color = 'purple'  # Token masqu√©\n",
    "        else:\n",
    "            color = 'cyan'  # Token de contexte\n",
    "        \n",
    "        plt.scatter(reduced_states[i, 0], reduced_states[i, 1], c=color, label=token)\n",
    "        plt.text(reduced_states[i, 0], reduced_states[i, 1], token, fontsize=9)\n",
    "\n",
    "    plt.xlabel(\"PC 1\")\n",
    "    plt.ylabel(\"PC 2\")\n",
    "    plt.title(f\"PCA of hidden state for one sentence at layer {number} \")\n",
    "    plt.legend(handles=[\n",
    "        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='cyan', markersize=10, label='Token de Contexte'),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=10, label='Token Sp√©cial'),\n",
    "        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='purple', markersize=10, label='Token Masqu√©')\n",
    "    ], loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "for j in range(13):\n",
    "    print(\"hugging face\")\n",
    "    plot_pca_hidden_state(hidden_states[j],tokens,j)\n",
    "    print(\"kb\")\n",
    "    plot_pca_hidden_state(hidden_states_kb[j],tokens,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA hidden states\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "text = \"Herr [MASK] von Ehrenheim : Anledningen till den framst√§llning \"\n",
    "inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "input_eb=exbert_tokenizer(text,return_tensors='pt').to(device)\n",
    "input_spa = swerick_tokenizer(text,return_tensors='pt').to(device)\n",
    "\n",
    "outputs = model_kb(**inputs,output_hidden_states=True)\n",
    "outputs_hugging = model_hugging_face(**inputs,output_hidden_states=True)\n",
    "output_eb=model_exbert(**input_eb,output_hidden_states=True)\n",
    "output_spa=mosaicBert(**input_spa,output_hidden_states=True)\n",
    "print(output_spa)\n",
    "all_hidden_states = outputs.hidden_states\n",
    "all_hidden_states_cpt = outputs_hugging.hidden_states\n",
    "all_hidden_states_eb = output_eb.hidden_states\n",
    "all_hidden_states_spa = output_spa.hidden_states\n",
    "\n",
    "index=2\n",
    "token_hidden_states = [layer_hidden_states[0, index].detach().cpu().numpy() for layer_hidden_states in all_hidden_states]\n",
    "token_hidden_states_cpt = [layer_hidden_states[0, index].detach().cpu().numpy() for layer_hidden_states in all_hidden_states_cpt]\n",
    "token_hidden_states_eb = [layer_hidden_states[0, index].detach().cpu().numpy() for layer_hidden_states in all_hidden_states_eb]\n",
    "#token_hidden_states_spa = [layer_hidden_states[0, index].detach().cpu().numpy() for layer_hidden_states in all_hidden_states_spa]\n",
    "\n",
    "pca_2d = PCA(n_components=2)\n",
    "token_hidden_states_2d = pca_2d.fit_transform(token_hidden_states)\n",
    "token_hidden_states_cpt_2d = pca_2d.fit_transform(token_hidden_states_cpt)\n",
    "token_hidden_states_eb_2d = pca_2d.fit_transform(token_hidden_states_eb)\n",
    "#token_hidden_states_spa_2d = pca_2d.fit_transform(token_hidden_states_spa)\n",
    "\n",
    "pca_3d = PCA(n_components=3)\n",
    "token_hidden_states_3d = pca_3d.fit_transform(token_hidden_states)\n",
    "token_hidden_states_cpt_3d = pca_3d.fit_transform(token_hidden_states_cpt)\n",
    "token_hidden_states_eb_3d = pca_3d.fit_transform(token_hidden_states_eb)\n",
    "#token_hidden_states_spa_3d = pca_3d.fit_transform(token_hidden_states_spa)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(len(token_hidden_states_2d)):\n",
    "    plt.scatter(token_hidden_states_2d[i, 0], token_hidden_states_2d[i, 1], label=f'Layer {i}')\n",
    "  \n",
    "plt.plot(token_hidden_states_2d[:, 0], token_hidden_states_2d[:, 1], linestyle='-', marker='o')\n",
    "plt.plot(token_hidden_states_cpt_2d[:, 0], token_hidden_states_cpt_2d[:, 1], linestyle='-', marker='o',color='red',label='cptBERT')\n",
    "plt.plot(token_hidden_states_eb_2d[:, 0], token_hidden_states_eb_2d[:, 1], linestyle='-', marker='o',color='green',label='sBERTex')\n",
    "#plt.plot(token_hidden_states_spa_2d[:, 0], token_hidden_states_spa_2d[:, 1], linestyle='-', marker='o',color='black',label='sparBERT')\n",
    "plt.title(f'2D Projection of Hidden States of Token {tokenizer.decode(inputs[\"input_ids\"][0][index])} through layers')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualisation en 3D\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(len(token_hidden_states_3d)):\n",
    "    ax.scatter(token_hidden_states_3d[i, 0], token_hidden_states_3d[i, 1], token_hidden_states_3d[i, 2], label=f'Layer {i}')\n",
    "ax.plot(token_hidden_states_3d[:, 0], token_hidden_states_3d[:, 1], token_hidden_states_3d[:, 2], linestyle='-', marker='o')\n",
    "ax.plot(token_hidden_states_cpt_3d[:, 0], token_hidden_states_cpt_3d[:, 1], token_hidden_states_cpt_3d[:, 2], linestyle='-', marker='o',color='red',label='cptBERT')\n",
    "ax.plot(token_hidden_states_eb_3d[:, 0], token_hidden_states_eb_3d[:, 1], token_hidden_states_eb_3d[:, 2], linestyle='-', marker='o',color='green',label='sBERTex')\n",
    "#ax.plot(token_hidden_states_spa_3d[:, 0], token_hidden_states_spa_3d[:, 1], token_hidden_states_spa_3d[:, 2], linestyle='-', marker='o',color='black',label='sparBERT')\n",
    "ax.set_title(f'3D Projection of Hidden States of Token {tokenizer.decode(inputs[\"input_ids\"][0][index])} through layer')\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(13):\n",
    "        combined_embeddings = np.concatenate([baseline_embeddings[layer], finetuned_embeddings[layer]])\n",
    "        tsne = TSNE(n_components=2, random_state=42)\n",
    "        X_tsne = tsne.fit_transform(combined_embeddings)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        for i, color in enumerate(['blue', 'red', 'orange', 'green']):\n",
    "            indices = [j for j, c in enumerate(colors) if c == color]\n",
    "            plt.scatter(X_tsne[indices, 0], X_tsne[indices, 1], c=color, label=color, alpha=0.5, edgecolors='w', s=50)\n",
    "\n",
    "        plt.title('t-SNE of Word Embeddings with Classification Results')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "num_words=500\n",
    "embedding_matrix_kb = model_kb.bert.embeddings.word_embeddings.weight.detach().cpu()\n",
    "embedding_matrix_cpt= model_hugging_face.bert.embeddings.word_embeddings.weight.detach().cpu()\n",
    "#words_of_interest = ['##nader', '##varo', '##sapparat', 'ned', 'beg√§r', '##ier', '##vens', 'replik', '##skri', '##ads', 'regionerna', '##skar', '##ositionen', 'f√∂rs√§kra', '##vot', '##fri', '##n√§ringen', '##oko', '##olin', 'fonden', '##√§ck', '##skill', '##kontakt', '##grip', '##raftt', 'Fru', '##m√§l', '##vari', 'Statsr√•det', 'Utskottet', '##¬£', '##ati', '##rift', 'Full', '##farlig', '##eminister', '##iter', 'Pro', '##ande', 'n√•gonting', 'Hultsfred', '##√∂tet', '##igen', '##speriod', 'Kungl', '##pekt', 'Onsdagen', '##kning', '##¬£', 'Kungl', 'Flott', '##s√§ttas', '##arbetar', '718', '##m√§ter', '##mt', 'fi', '##NE', 'godk√§nnas', 'JOHANSSON', 'Onsdagen', '##taga', 'M√•ndagen', 'Nr', '##hai', 'talman', 'Riksdagen']\n",
    "#word_indices = [tokenizer.vocab[word] for word in words_of_interest if word in tokenizer.vocab]\n",
    "words_of_interest= list(tokenizer.vocab.keys())[:num_words]\n",
    "selected_embeddings_kb = embedding_matrix_kb[:num_words, :]\n",
    "selected_embeddings_cpt = embedding_matrix_cpt[:num_words, :]\n",
    "tsne = TSNE(n_components=2, random_state=42,perplexity=30)\n",
    "embedding_2d = tsne.fit_transform(selected_embeddings_kb)\n",
    "\n",
    "# Tracer les embeddings 2D\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, word in enumerate(words_of_interest):\n",
    "    x, y = embedding_2d[i, :]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, (x, y), fontsize=9)\n",
    "\n",
    "plt.title('2D t-SNE Representation of Word Embeddings')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.show()\n",
    "\n",
    "embedding_cpt = tsne.fit_transform(selected_embeddings_cpt)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, word in enumerate(words_of_interest):\n",
    "    x, y = embedding_cpt[i, :]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, (x, y), fontsize=9)\n",
    "\n",
    "plt.title('2D t-SNE Representation of Word Embeddings for cptBERT')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls.predictions.transform.LayerNorm.weight\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparaison of weights for different model\n",
    "import numpy as np\n",
    "\n",
    "weights_kb = comprehension_model.get_model_weights(model_kb)\n",
    "weights_finetuned = comprehension_model.get_model_weights(model_hugging_face)\n",
    "\n",
    "weight_diffs = {}\n",
    "for key in weights_kb.keys():\n",
    "    weight_diffs[key] = weights_finetuned[key] - weights_kb[key]\n",
    "    if (np.linalg.norm(weight_diffs[key])/weight_diffs[key].size) > 0.04 :\n",
    "        print(key)\n",
    "    #     print(np.linalg.norm(weight_diffs[key],2))\n",
    "    #     print(weight_diffs[key].size)\n",
    "    #     print( np.linalg.norm(weight_diffs[key])/weight_diffs[key].size)\n",
    "    \n",
    "\n",
    "weight_diffs[\"cls.predictions.decoder.bias\"] = model_hugging_face.cls.predictions.decoder.bias.detach().cpu().numpy() - model_kb.cls.predictions.decoder.bias.detach().cpu().numpy()\n",
    "weight_diffs[\"cls.predictions.decoder.weight\"] = model_hugging_face.cls.predictions.decoder.weight.detach().cpu().numpy() - model_kb.cls.predictions.decoder.weight.detach().cpu().numpy()\n",
    "norms = [(np.linalg.norm(weight_diffs[key])/weight_diffs[key].size) for key in weight_diffs.keys()]\n",
    "embedding_indices = [list(range(0, 5))]\n",
    "encoder_layers= list(range(5 ,5 +16*(11)))  # Adjust based on actual sublayers\n",
    "head_layer_indices = list(range(181, len(norms)))\n",
    "\n",
    "xticks_positions = [0, len(encoder_layers)//2 + len(embedding_indices), len(norms)-1]\n",
    "xticks_labels = ['Embedding Layers', 'Encoder Layers', 'Head Layers']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(range(len(norms)), norms)\n",
    "plt.axvline(x=5.5, color='grey', linestyle='--')\n",
    "plt.axvline(x=len(embedding_indices) + len(encoder_layers) - 0.5, color='grey', linestyle='--')\n",
    "plt.xticks(xticks_positions, xticks_labels, rotation=0)\n",
    "plt.ylabel('Frobenius Norm of Weight Differences')\n",
    "plt.xlabel('Sublayers')\n",
    "plt.title('Comparison of Weight Changes in BERT Layers')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hugging_face.state_dict()[\"bert.encoder.layer.0.attention.self.key.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "with PdfPages('weight_distribution_scratch.pdf') as pdf:\n",
    "    for name,param in mosaicBert.named_parameters():\n",
    "        layer_name = name\n",
    "        print(name)\n",
    "        split_name =name.split('.')\n",
    "        layer = split_name[3]\n",
    "        print(layer)\n",
    "        #comprehension_model.plot_weight_distributions(model_hugging_face, model_kb, layer_name)\n",
    "        if \"attention.self.Wqkv\"  in name and \"weight\" in name:\n",
    "            weights2 = model_kb.state_dict()[f\"bert.encoder.layer.{str(layer)}.attention.self.query.{split_name[-1]}\"].flatten().cpu().numpy()\n",
    "            weights1 = mosaicBert.state_dict()[layer_name][:768,:].flatten().cpu().numpy()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(weights1, bins=100, alpha=0.5, label='finetuned Model',density=True)\n",
    "            plt.hist(weights2, bins=100, alpha=0.5, label='Baseline Model',density=True)\n",
    "            plt.title(f\"Weight Distribution Comparison for {layer_name}\")\n",
    "            plt.xlabel(\"Weight values\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            weights2 = model_kb.state_dict()[f\"bert.encoder.layer.{str(layer)}.attention.self.key.{split_name[-1]}\"].flatten().cpu().numpy()\n",
    "            weights1 = mosaicBert.state_dict()[layer_name][768:1536,:].flatten().cpu().numpy()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(weights1, bins=100, alpha=0.5, label='finetuned Model',density=True)\n",
    "            plt.hist(weights2, bins=100, alpha=0.5, label='Baseline Model',density=True)\n",
    "            plt.title(f\"Weight Distribution Comparison for {layer_name}\")\n",
    "            plt.xlabel(\"Weight values\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            weights2 = model_kb.state_dict()[f\"bert.encoder.layer.{str(layer)}.attention.self.value.{split_name[-1]}\"].flatten().cpu().numpy()\n",
    "            weights1 = mosaicBert.state_dict()[layer_name][1536:,:].flatten().cpu().numpy()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(weights1, bins=100, alpha=0.5, label='finetuned Model',density=True)\n",
    "            plt.hist(weights2, bins=100, alpha=0.5, label='Baseline Model',density=True)\n",
    "            plt.title(f\"Weight Distribution Comparison for {layer_name}\")\n",
    "            plt.xlabel(\"Weight values\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        elif  \"attention.self.Wqkv\" in name and \"bias\" in name :\n",
    "            weights2 = model_kb.state_dict()[f\"bert.encoder.layer.{str(layer)}.attention.self.query.{split_name[-1]}\"].flatten().cpu().numpy()\n",
    "            weights1 = mosaicBert.state_dict()[layer_name][:768].flatten().cpu().numpy()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(weights1, bins=100, alpha=0.5, label='finetuned Model',density=True)\n",
    "            plt.hist(weights2, bins=100, alpha=0.5, label='Baseline Model',density=True)\n",
    "            plt.title(f\"Weight Distribution Comparison for {layer_name}\")\n",
    "            plt.xlabel(\"Weight values\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            weights2 = model_kb.state_dict()[f\"bert.encoder.layer.{str(layer)}.attention.self.key.{split_name[-1]}\"].flatten().cpu().numpy()\n",
    "            weights1 = mosaicBert.state_dict()[layer_name][768:1536].flatten().cpu().numpy()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(weights1, bins=100, alpha=0.5, label='finetuned Model',density=True)\n",
    "            plt.hist(weights2, bins=100, alpha=0.5, label='Baseline Model',density=True)\n",
    "            plt.title(f\"Weight Distribution Comparison for {layer_name}\")\n",
    "            plt.xlabel(\"Weight values\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            weights2 = model_kb.state_dict()[f\"bert.encoder.layer.{str(layer)}.attention.self.value.{split_name[-1]}\"].flatten().cpu().numpy()\n",
    "            weights1 = mosaicBert.state_dict()[layer_name][1536:].flatten().cpu().numpy()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(weights1, bins=100, alpha=0.5, label='finetuned Model',density=True)\n",
    "            plt.hist(weights2, bins=100, alpha=0.5, label='Baseline Model',density=True)\n",
    "            plt.title(f\"Weight Distribution Comparison for {layer_name}\")\n",
    "            plt.xlabel(\"Weight values\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close() \n",
    "        elif \"mlp.gated_layers\"  in name :\n",
    "            \n",
    "            weights2 = model_kb.state_dict()[f\"bert.encoder.layer.{str(layer)}.intermediate.dense.{split_name[-1]}\"].flatten().cpu().numpy()\n",
    "            weights1 = mosaicBert.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(weights1, bins=100, alpha=0.5, label='finetuned Model',density=True)\n",
    "            plt.hist(weights2, bins=100, alpha=0.5, label='Baseline Model',density=True)\n",
    "            plt.title(f\"Weight Distribution Comparison for {layer_name}\")\n",
    "            plt.xlabel(\"Weight values\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "        elif \"mlp.wo\" in name :\n",
    "            weights2 = model_kb.state_dict()[f\"bert.encoder.layer.{str(layer)}.output.dense.{split_name[-1]}\"].flatten().cpu().numpy()\n",
    "            weights1 = mosaicBert.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(weights1, bins=100, alpha=0.5, label='finetuned Model',density=True)\n",
    "            plt.hist(weights2, bins=100, alpha=0.5, label='Baseline Model',density=True)\n",
    "            plt.title(f\"Weight Distribution Comparison for {layer_name}\")\n",
    "            plt.xlabel(\"Weight values\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "        elif \"mlp.layernorm\"  in name :\n",
    "            \n",
    "            weights2 = model_kb.state_dict()[f\"bert.encoder.layer.{str(layer)}.output.LayerNorm.{split_name[-1]}\"].flatten().cpu().numpy()\n",
    "            weights1 = mosaicBert.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(weights1, bins=100, alpha=0.5, label='finetuned Model',density=True)\n",
    "            plt.hist(weights2, bins=100, alpha=0.5, label='Baseline Model',density=True)\n",
    "            plt.title(f\"Weight Distribution Comparison for {layer_name}\")\n",
    "            plt.xlabel(\"Weight values\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "        elif \"cls.predictions.decoder\" in name:\n",
    "            continue\n",
    "            \n",
    "        else :\n",
    "            weights1 = mosaicBert.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "            weights2 = model_kb.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.hist(weights1, bins=100, alpha=0.5, label='finetuned Model',density=True)\n",
    "            plt.hist(weights2, bins=100, alpha=0.5, label='Baseline Model',density=True)\n",
    "            plt.title(f\"Weight Distribution Comparison for {layer_name}\")\n",
    "            plt.xlabel(\"Weight values\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.legend()\n",
    "            pdf.savefig()\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model_exbert.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer_name = \"cls.predictions.transform.dense.weight\"\n",
    "\n",
    "weights2 = model_kb.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "weights1 = mosaicBert.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(weights1, bins=100, alpha=0.5, label='finetuned Model',density=True)\n",
    "plt.hist(weights2, bins=100, alpha=0.5, label='Baseline Model',density=True)\n",
    "plt.title(f\"Weight Distribution Comparison for {layer_name} for SparBERT\")\n",
    "plt.xlabel(\"Weight values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "print(hidden_states1[0].shape)\n",
    "i=8\n",
    "hidden_states1,logits1=get_embeddings_bis(model_kb,valid_sentence_filtered [i],tokenizer)\n",
    "hidden_states2,logits2=get_embeddings_bis(model_hugging_face,valid_sentence_filtered [i],tokenizer)\n",
    "#masked_positions =[idx for idx, token in enumerate(valid_filtered_dataset[i]['input_ids']) if token == tokenizer.mask_token_id]\n",
    "index = valid_sentence_filtered [i]['labels'].index(token_id)\n",
    "print(token_id)\n",
    "print(tokenizer.decode(valid_sentence_filtered[i]['input_ids']))\n",
    "print(tokenizer.decode(torch.argmax(F.softmax(logits1.squeeze()[index], dim=-1)).item()))\n",
    "print(tokenizer.decode(torch.argmax(F.softmax(logits2.squeeze()[index], dim=-1)).item()))\n",
    "for j in range(len(hidden_states1)) :\n",
    "    print(tokenizer.decode((valid_sentence_filtered[i]['labels'][index])))\n",
    "    print('hidden layer ',j)\n",
    "    plt.figure(figsize=(10,6))\n",
    "   #plt.hist(hidden_states1[j][0][index].detach().cpu().numpy(), bins=100, alpha=0.5, label='Baseline Model')\n",
    "    plt.hist(hidden_states1[j][0][0].detach().cpu().numpy(), bins=100, alpha=0.5, label='Baseline Model cls')\n",
    "    #plt.hist(hidden_states2[j][0][index].detach().cpu().numpy(), bins=100, alpha=0.5, label='Fine-tuned Model')\n",
    "    plt.hist(hidden_states2[j][0][0].detach().cpu().numpy(), bins=100, alpha=0.5, label='finetuned Model cls')\n",
    "    plt.xlabel('weight')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "checkpoint_directory = \"/home/laurinemeier/swerick/finetuning/finetuning_hugging_whitespace-finetuned-imdb\"\n",
    "checkpoint_files = os.listdir(checkpoint_directory)\n",
    "checkpoint_files.sort(key=lambda x: int(re.search(r'checkpoint-(\\d+)', x).group(1)))\n",
    "selected_checkpoints = [checkpoint_files[i] for i in range(0, len(checkpoint_files), 10)]\n",
    "weight1 = model_kb.state_dict()[\"bert.embeddings.word_embeddings.weight\"].flatten().cpu().numpy()\n",
    "print(\"std kb\", np.std(weight1))\n",
    "for name in selected_checkpoints :\n",
    "    print(name)\n",
    "    model_hugging =AutoModelForMaskedLM.from_pretrained(checkpoint_directory + '/'+name)\n",
    "    weights2 = model_hugging.state_dict()[\"bert.embeddings.word_embeddings.weight\"].flatten().cpu().numpy()\n",
    "    print(np.std(weights2))\n",
    "    model_hugging.to(device)\n",
    "    comprehension_model.plot_weight_distributions(model_hugging, model_kb, \"bert.embeddings.word_embeddings.weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states1 = comprehension_model.get_embeddings(model_kb, small_valid_dataloader, tokenizer)\n",
    "hidden_states2 = comprehension_model.get_embeddings(model_hugging_face, small_valid_dataloader, tokenizer)\n",
    "\n",
    "for i in range(len(hidden_states1)):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(hidden_states1[i].flatten(), bins=100, alpha=0.5, label='Baseline Model')\n",
    "        plt.hist(hidden_states2[i].flatten(), bins=100, alpha=0.5, label='Fine-tuned Model')\n",
    "        plt.title(f\"Hidden States Distribution Comparison for Layer {i}\")\n",
    "        plt.xlabel(\"Hidden States Values\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evolution of a specific layer through epochs\n",
    "checkpoint_directory = 'finetuning/finetuning_hugging_whitespace-finetuned-imdb'\n",
    "comprehension_model.evolution_specific_layer_weight(chekpoint_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study of Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(mean_similarities,x_label='Layer Number',y_label='Average Cosine Similarity',title='Average Layer-wise Cosine Similarity between hidden_states Across Validation Dataset'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(len(mean_similarities)), mean_similarities, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "mean_similarities_hidden_states,mean_similarities_attention,diff_tot = comprehension_model.extract_and_compare_activations(model_kb, model_hugging_face, valid_filtered_dataloader,token_id)\n",
    "print(\"Layer-wise cosine similarities:\", mean_similarities_hidden_states)\n",
    "\n",
    "\n",
    "plot_results(mean_similarities_hidden_states)\n",
    "plot_results(mean_similarities_attention,'Attention Layer Number',title='Average Attention Layer-wise Cosine Similarity between Attention values Across Validation Dataset')\n",
    "plot_results(diff_tot,'Layer Number',title='Average Norm difference between hidden states  Across Validation Dataset for token {words}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def cosine_similarity(tensor1, tensor2):\n",
    "    # Ensure tensors are flattened (1D) to compute vector cosine similarity\n",
    "    tensor1_flat = tensor1.view(-1)\n",
    "    tensor2_flat = tensor2.view(-1)\n",
    "    cos_sim = torch.nn.functional.cosine_similarity(tensor1_flat.unsqueeze(0), tensor2_flat.unsqueeze(0))\n",
    "    return cos_sim.item()\n",
    "\n",
    "\n",
    "# Define the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def plot_results(similarities, x_label='Layer Number', y_label='Average Cosine Similarity', title='Average Layer-wise Cosine Similarity between hidden_states Across Validation Dataset'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(len(similarities)), similarities, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def compare_ffn_contributions(model_pre, model_post, dataloader):\n",
    "    similarities_pre = []\n",
    "   #similarities_post = []\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        batch = {k: batch[k].to(device) for k in batch.keys()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pre_output = model_pre(**batch, output_hidden_states=True)\n",
    "            pre_activations = pre_output.hidden_states\n",
    "            post_output = model_post(**batch, output_hidden_states=True)\n",
    "            post_activations = post_output.hidden_states\n",
    "    \n",
    "        pre_contribution = [(pre_activations[layer+1] -pre_activations[layer]) for layer in range(len(pre_activations)-1)]\n",
    "        post_contribution = [(post_activations[layer+1] - post_activations[layer]) for layer in range(len(post_activations)-1)]\n",
    "\n",
    "        pre_activation = [cosine_similarity(pre_contribution[i],post_contribution[i]) for i in range (len(pre_contribution))]\n",
    "       # post_activation = [cosine_similairity(post_contribution[i] for i in range (len(post_contribution)))]\n",
    "        similarities_pre.append(pre_activation)\n",
    "       # similarities_post.append(post_contribution)\n",
    "        \n",
    "        del pre_activations\n",
    "        del post_activations\n",
    "        del pre_output\n",
    "        del post_output\n",
    "    \n",
    "    similarities_pre = np.mean(np.array(similarities_pre), axis=0)\n",
    "   # similarities_post = np.mean(np.array(similarities_post), axis=0)\n",
    "    \n",
    "    return similarities_pre\n",
    "# Example usage\n",
    "mean_similarity_pr = compare_ffn_contributions(model_kb, model_hugging_face, small_valid_dataloader)\n",
    "\n",
    "plot_results(mean_similarity_pr, x_label='Layer n+1 - Layer n', y_label='Average Cosine Similarity', title='Average Layer-wise Cosine Similarity for differences consecutive layers of KB Bert Model and cptBERT')\n",
    "#plot_results(mean_similarity_post, label='Layer n+1 - Layer n', x_label='Layer n+1 - Layer n', y_label='Average Cosine Similarity', title='Average Layer-wise Cosine Similarity for Finetuned Model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# see if final layers is similar\n",
    "\n",
    "\n",
    "def cosine_similarity(tensor1, tensor2):\n",
    "    # Ensure tensors are flattened (1D) to compute vector cosine similarity\n",
    "    tensor1_flat = tensor1.view(-1)\n",
    "    tensor2_flat = tensor2.view(-1)\n",
    "    cos_sim = torch.nn.functional.cosine_similarity(tensor1_flat.unsqueeze(0), tensor2_flat.unsqueeze(0))\n",
    "    return cos_sim.item()\n",
    "\n",
    "\n",
    "def interpolate_to_length(tensor, target_length):\n",
    "    # Interpolation lin√©aire pour redimensionner le tenseur √† la longueur cible\n",
    "    current_length = tensor.shape[1]\n",
    "    if current_length == target_length:\n",
    "        return tensor\n",
    "    # Cr√©er un tenseur avec la longueur cible en utilisant l'interpolation lin√©aire\n",
    "    interpolated_tensor = F.interpolate(tensor.transpose(1, 2), size=target_length, mode='linear', align_corners=False).transpose(1, 2)\n",
    "    return interpolated_tensor\n",
    "\n",
    "def plot_results(similarities, x_label='Layer Number', y_label='Average Cosine Similarity', title='Average Layer-wise Cosine Similarity between hidden_states Across Validation Dataset'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(len(similarities)), similarities, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "model_hugging_face.to(device)\n",
    "model_exbert.to(device)\n",
    "#mosaicBert.to(device)  \n",
    "model_kb.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cosine_cpt_final=[]\n",
    "cosine_eb_final=[]\n",
    "cosine_spa_final=[]\n",
    "hidden_states=[]\n",
    "cosine_embedding=[]\n",
    "diff_final_kb=[]\n",
    "diff_final_eb=[]\n",
    "embedding_cpt = model_hugging_face.bert.embeddings\n",
    "embedding_kb=model_kb.bert.embeddings\n",
    "\n",
    "# random_vector = torch.randn_like(hidden_states[0]).to(device)\n",
    "torch.manual_seed(33)\n",
    "for layer in range(12):\n",
    "\n",
    "    cosine_cpt=[]\n",
    "    cosine_eb=[]\n",
    "    cosine_spa=[]\n",
    "    diff_kb=[]\n",
    "    diff_eb=[]\n",
    "    last_layer_kb = model_kb.bert.encoder.layer[layer]\n",
    "    last_layer_cpt = model_hugging_face.bert.encoder.layer[layer]\n",
    "    last_layer_eb=model_exbert.bert.encoder.layer[layer]\n",
    "       \n",
    "    for batch in small_valid_dataloader :\n",
    "        batch={key:value.to(device) for key,value in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            output=model_kb(**batch,output_hidden_states=True)\n",
    "        if layer ==0:\n",
    "            embedding = embedding_cpt(batch[\"input_ids\"])\n",
    "            \n",
    "        hidden_states=output.hidden_states[layer].to(device)\n",
    "\n",
    "      \n",
    "        # if layer ==0:\n",
    "        #     embedding = embedding_cpt(random_embedding)  \n",
    "        #     embeddingkb= embedding_kb(random_embedding)\n",
    "        hs_kb=last_layer_kb(hidden_states)\n",
    "        hs_cpt=last_layer_cpt(hidden_states)\n",
    "        hs_eb=last_layer_eb(hidden_states)\n",
    "        \n",
    "        \n",
    "                \n",
    "        # if layer==0:\n",
    "        #     cosine_embedding.append(cosine_similarity(embeddingkb,embedding))\n",
    "            \n",
    "        cosine_cpt.append(cosine_similarity(hs_kb[0],hs_cpt[0]))\n",
    "        cosine_eb.append(cosine_similarity(hs_kb[0],hs_eb[0]))\n",
    "        cosine_spa.append(cosine_similarity(hs_eb[0],hs_cpt[0]))\n",
    "        diff_kb.append(cosine_similarity(hs_kb[0]-hidden_states,hs_cpt[0]-hidden_states))\n",
    "        diff_eb.append(cosine_similarity(hs_kb[0]-hidden_states,hs_eb[0]-hidden_states))\n",
    "        # if layer==0:\n",
    "        #     cosine_cpt_final.append(np.mean(cosine_embedding))\n",
    "    cosine_cpt_final.append(np.mean(cosine_cpt))\n",
    "    cosine_eb_final.append(np.mean(cosine_eb))\n",
    "    cosine_spa_final.append(np.mean(cosine_spa,axis=0))\n",
    "    diff_final_kb.append(np.mean(diff_kb))\n",
    "    diff_final_eb.append(np.mean(diff_eb))\n",
    "    \n",
    "    print(np.mean(cosine_cpt))\n",
    "    print(np.mean(cosine_eb))   \n",
    "            \n",
    "\n",
    "plot_results(cosine_cpt_final,x_label='Layer',title='Avg cosine similarity between KB bert and cptBERT without propagation')\n",
    "plot_results(cosine_eb_final,x_label='Layer',title='Avg cosine similarity between KB bert and sBERTex without propagation')\n",
    "plot_results(cosine_spa_final,x_label='Layer',title='Avg cosine similarity between cptBERT and sBERTex without propagation')\n",
    "plot_results(diff_final_kb,x_label='Layer',title='Avg cosine similarity between differences of consecutives layers cptBERT and KB bert without propagation')\n",
    "plot_results(diff_final_eb,x_label='Layer',title='Avg cosine similarity between differences of consecutives layers sBERTex and KB bert without propagation')\n",
    "# # print(\"cosine similarity spa\",np.mean(cosine_spa,axis=0))\n",
    "    \n",
    "# sentence = \"Herr [MASK] von Ehrenheim : √Ñfven\"\n",
    "# input_kb=tokenizer(sentence,return_tensors='pt').to(device)\n",
    "# input_eb=exbert_tokenizer(sentence,return_tensors='pt').to(device)\n",
    "# model_kb.to(device)\n",
    "# model_exbert.to(device)\n",
    "\n",
    "\n",
    "# output1=model_kb(**input_kb,output_hidden_states=True)\n",
    "# output2=model_exbert(**input_eb,output_hidden_states=True)\n",
    "# pre_activations = output1.hidden_states\n",
    "# post_activation=output2.hidden_states\n",
    "\n",
    "# target_length=len(pre_activations[0][0])\n",
    "# print(target_length)\n",
    "\n",
    "# pre_contribution = [interpolate_to_length((pre_activations[layer+1] -pre_activations[layer]),target_length) for layer in range(len(pre_activations)-1)]\n",
    "# post_contribution = [interpolate_to_length((post_activation[layer+1] - post_activation[layer]),target_length) for layer in range(len(post_activation)-1)]\n",
    "\n",
    "# cosine_activation = [cosine_similarity(pre_contribution[i],post_contribution[i]) for i in range (len(pre_contribution))]\n",
    "\n",
    "\n",
    "# plot_results(cosine_activation,x_label=\"Layer\",y_label=\"Average Cosine Similairyt difference\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "text=\"Herr [MASK] von Ehrenheim : Anledningen till den framst√§llning\"\n",
    "input_kb=tokenizer(text,return_tensors='pt').to(device)\n",
    "output=model_kb(**input_kb,output_hidden_states=True)\n",
    "\n",
    "hidden_states=output.hidden_states[-1].to(device)\n",
    "head_layer_kb=model_kb.cls\n",
    "head_layer_cpt=model_hugging_face.cls\n",
    "head_layer_eb=model_exbert.cls\n",
    "head_layer_spa=mosaicBert.cls\n",
    "output_kb = head_layer_kb(hidden_states)\n",
    "output_cpt = head_layer_cpt(hidden_states)\n",
    "output_eb = head_layer_eb(hidden_states)\n",
    "output_spa=head_layer_spa(hidden_states)\n",
    "print(output_kb.shape)\n",
    "\n",
    "softmax_probs_kb = F.softmax(output_kb.squeeze()[2], dim=-1)\n",
    "sorted_probs_kb, sorted_indices_kb = torch.sort(softmax_probs_kb, descending=True)\n",
    "sorted_tokens_kb = [tokenizer.decode([idx]) for idx in sorted_indices_kb[:10]]\n",
    "print(sorted_tokens_kb)\n",
    "\n",
    "softmax_probs_kb = F.softmax(output.logits.squeeze()[2], dim=-1)\n",
    "sorted_probs_kb, sorted_indices_kb = torch.sort(softmax_probs_kb, descending=True)\n",
    "sorted_tokens_kb = [tokenizer.decode([idx]) for idx in sorted_indices_kb[:10]]\n",
    "print(sorted_tokens_kb)\n",
    "\n",
    "softmax_probs_cpt = F.softmax(output_cpt.squeeze()[2], dim=-1)\n",
    "sorted_probs_cpt, sorted_indices_cpt = torch.sort(softmax_probs_cpt, descending=True)\n",
    "sorted_tokens_cpt= [tokenizer.decode([idx]) for idx in sorted_indices_cpt[:10]]\n",
    "print(sorted_tokens_cpt)\n",
    "\n",
    "softmax_probs_eb = F.softmax(output_eb.squeeze()[2], dim=-1)\n",
    "sorted_probs_eb, sorted_indices_eb = torch.sort(softmax_probs_eb, descending=True)\n",
    "sorted_tokens_eb = [exbert_tokenizer.decode([idx]) for idx in sorted_indices_eb[:10]]\n",
    "print(sorted_tokens_eb)\n",
    "\n",
    "\n",
    "softmax_probs_spa = F.softmax(output_spa.squeeze()[2], dim=-1)\n",
    "sorted_probs_spa, sorted_indices_spa = torch.sort(softmax_probs_spa, descending=True)\n",
    "sorted_tokens_spa = [swerick_tokenizer.decode([idx]) for idx in sorted_indices_spa[:10]]\n",
    "print(sorted_tokens_spa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity between layers\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_and_compare_feed_forward_weights(model_pre, model_post, dataloader):\n",
    "    similarities_attention = {}\n",
    "    similarities_query = {}\n",
    "    similarities_key = {}\n",
    "    similarities_value = {}\n",
    "    for (name_base, param_base), (name_fine, param_fine) in zip(model_kb.named_parameters(), model_hugging_face.named_parameters()):\n",
    "        if \"cls.predictions.transform.dense.weight\" in name_base :\n",
    "            sim = cosine_similarity(param_base, param_fine)\n",
    "            similarities_attention[name_base]=sim\n",
    "            print(f\"{name_base} - Cosine Similarity: {sim}\")\n",
    "        if  \"cls.predictions.transform.dense.bias\" in name_base:\n",
    "            sim = cosine_similarity(param_base, param_fine)\n",
    "            similarities_query[name_base]=sim\n",
    "        if  \"attention.self.key.bias\" in name_base:\n",
    "            sim = cosine_similarity(param_base, param_fine)\n",
    "            similarities_key[name_base]=sim\n",
    "        if  \"attention.self.value.bias\" in name_base:\n",
    "            sim = cosine_similarity(param_base, param_fine)\n",
    "            similarities_value[name_base]=sim\n",
    "            print(f\"{name_base} - Cosine Similarity: {sim}\")\n",
    "\n",
    "    return similarities_attention,similarities_query,similarities_key,similarities_value\n",
    "       \n",
    "def cosine_similarity(tensor1, tensor2):\n",
    "    # Ensure tensors are flattened (1D) to compute vector cosine similarity\n",
    "    tensor1_flat = tensor1.view(-1)\n",
    "    tensor2_flat = tensor2.view(-1)\n",
    "    cos_sim = torch.nn.functional.cosine_similarity(tensor1_flat.unsqueeze(0), tensor2_flat.unsqueeze(0))\n",
    "    return cos_sim.item()\n",
    "\n",
    "\n",
    "\n",
    "def plot_results(similarities,label,x_label='Layer Number',y_label='Average Cosine Similarity',title='Average Layer-wise Cosine Similarity between hidden_states Across Validation Dataset'):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(len(similarities)), similarities, marker='o', linestyle='-', color='b',)\n",
    "    plt.xlabel(label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "mean_similarities_attention,mean_similarities_query,mean_similarities_key,mean_similarities_value = extract_and_compare_feed_forward_weights(model_kb, model_hugging_face, valid_dataloader)\n",
    "similarity_attention=[mean_similarities_attention[i] for i in mean_similarities_attention.keys()]\n",
    "similarity_query=[mean_similarities_query[i] for i in mean_similarities_query.keys()]\n",
    "similarity_key=[mean_similarities_key[i] for i in mean_similarities_key.keys()]\n",
    "similarity_value=[mean_similarities_value[i] for i in mean_similarities_value.keys()]\n",
    "\n",
    "\n",
    "\n",
    "plot_results(similarity_attention,label = mean_similarities_attention.keys(),title='layer wise cosine similarity between weights for attention.output.dense')\n",
    "plot_results(similarity_query,label = mean_similarities_query.keys(),title='layer wise cosine similarity between weights for attention.self.query')\n",
    "plot_results(similarity_key,label = mean_similarities_key.keys(),title='layer wise cosine similarity between weights for attention.self.key')\n",
    "plot_results(similarity_value,label = mean_similarities_value.keys(),title='layer wise cosine similarity between weights for attention.self.value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text,model):\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs,output_hidden_states=True)\n",
    "        \n",
    "    embeddings = outputs.hidden_states\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_train = [get_embeddings(phrase,model_kb) for phrase in date_dataset[\"train\"][\"content\"][:5]]\n",
    "print(len(embeddings_train))\n",
    "print(len(embeddings_train[0]))\n",
    "embeddings_test = [get_embeddings(phrase,model_kb) for phrase in date_dataset[\"test\"][\"content\"][:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge probing : predicting noun  \n",
    "import numpy as np \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "        \n",
    "def extract_and_classify(dataset, model,length):\n",
    "    layer_accuracies = []\n",
    "    with torch.no_grad():\n",
    "        for layer_index in range(model.config.num_hidden_layers + 1):  # Include the embedding layer\n",
    "            embeddings_train = [get_embeddings(phrase,model_kb) for phrase in dataset[\"train\"][\"content\"][:length]]\n",
    "            train_embeddings =[sentence[layer_index] for sentence in embeddings_train] \n",
    "            train_labels = date_dataset[\"train\"][\"reform_label\"][:length]\n",
    "            print(train_embeddings)\n",
    "            print(len(train_labels))\n",
    "            embeddings_test = [get_embeddings(phrase,model_kb) for phrase in dataset[\"test\"][\"content\"][:length]]\n",
    "            test_embeddings =[sentence[layer_index] for sentence in embeddings_test] \n",
    "            testlabels = date_dataset[\"test\"][\"reform_label\"][:length]\n",
    "    \n",
    "            clf = LogisticRegression()\n",
    "            clf.fit(train_embeddings, train_labels)\n",
    "            y_pred = clf.predict(test_embeddings)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(test_labels, y_pred)\n",
    "            layer_accuracies.append((layer_index, accuracy))\n",
    "    \n",
    "    return layer_accuracies\n",
    "\n",
    "\n",
    "accuracies = extract_and_classify(date_dataset, model_kb,5)\n",
    "\n",
    "# Output the accuracies for each layer\n",
    "for layer, acc in accuracies:\n",
    "    print(f\"Layer {layer}: Accuracy {acc}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings =[sentence[1] for sentence in embeddings_train] \n",
    "len(train_embeddings[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = date_dataset[\"train\"][\"content\"][0]\n",
    "input = tokenizer(input,return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "data_collator = preprocessing.data_collector_masking(tokenizer,0.15)\n",
    "input=data_collator([input])\n",
    "collated_inputs = {key: value.squeeze(1) for key, value in input.items()}\n",
    "output =model_kb(collated_inputs[\"input_ids\"],attention_mask=collated_inputs[\"attention_mask\"],labels =collated_inputs[\"labels\"],output_hidden_states=True)\n",
    "hidden_states = output.hidden_states\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(examples,model):\n",
    "  # take a batch of images\n",
    "  images = examples['content']\n",
    "  images = tokenizer(images,return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
    "  input=data_collator([images])\n",
    "  collated_inputs = {key: value.squeeze(1) for key, value in input.items()}\n",
    "  with torch.no_grad():\n",
    "    output =model(collated_inputs[\"input_ids\"],attention_mask=collated_inputs[\"attention_mask\"],labels =collated_inputs[\"labels\"],output_hidden_states=True)\n",
    "  hidden_states = output.hidden_states\n",
    "  # add features of each layer\n",
    "  for i in range(len(hidden_states)):\n",
    "      features = torch.mean(hidden_states[i], dim=1)\n",
    "      examples[f'features_{i}'] = features.cpu().detach().numpy()\n",
    "  \n",
    "  return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset_train_bis=Dataset.from_dict(date_dataset[\"train\"][100:150]).map(lambda example :extract_features(example,model_hugging_face), batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset_test_bis = Dataset.from_dict(date_dataset[\"test\"][:100]).map(lambda example :extract_features(example,model_hugging_face), batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset_test['features_4']==encoded_dataset_test_bis['features_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "def scores_linear_prob(train_dataset,test_dataset):\n",
    "    train_dataset = train_dataset\n",
    "    test_dataset = test_dataset\n",
    "\n",
    "    scores = dict()\n",
    "    for i in range(model_kb.config.num_hidden_layers + 1):\n",
    "        train_features = torch.Tensor(train_dataset[f'features_{i}']).squeeze(1)\n",
    "        test_features = torch.Tensor(test_dataset[f'features_{i}']).squeeze(1)\n",
    "        lr_clf = LogisticRegression()\n",
    "        lr_clf.fit(train_features, train_dataset['reform_label'])\n",
    "        # compute accuracy on training + test set\n",
    "        #training_score = lr_clf.score(train_features, train_dataset['reform_label'])\n",
    "        #test_score = lr_clf.score(test_features, test_dataset['reform_label'])\n",
    "        #scores[f'features_{i}'] = (training_score, test_score)\n",
    "\n",
    "        train_preds = lr_clf.predict(train_features)\n",
    "        test_preds = lr_clf.predict(test_features)\n",
    "        training_f1 = f1_score(train_dataset['reform_label'], train_preds, average='macro')\n",
    "        test_f1 = f1_score(test_dataset['reform_label'], test_preds, average='macro')\n",
    "        \n",
    "        scores[f'features_{i}'] = (training_f1, test_f1)\n",
    "        \n",
    "    return scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swerick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
