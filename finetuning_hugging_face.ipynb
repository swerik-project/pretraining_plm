{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at KBLab/bert-base-swedish-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"KBLab/bert-base-swedish-cased\"\n",
    "model = preprocessing.create_model_MLM(model_checkpoint)\n",
    "model= model.from_pretrained(\"finetuning_hugging-finetuned-imdb/checkpoint-259384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =preprocessing.create_tokenizer(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['protocole', 'texte'],\n",
      "        num_rows: 12463\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['protocole', 'texte'],\n",
      "        num_rows: 2629\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_files = {\"train\": \"swerick_data_random_train.pkl\", \"test\": \"swerick_data_random_test.pkl\"}\n",
    "swerick_dataset = load_dataset(\"pandas\",data_files=data_files)\n",
    "print(swerick_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e68d5561fb5479eb45a49529eba3693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40de6ab631e4d4aab0bb37fb1727b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 12463\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 2629\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets =preprocessing.tokenize_dataset(swerick_dataset,tokenizer)\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ba852bf467454fadc51cb5df46977f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12463 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce93a7c64854362a93ddb46f39c4a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 3681534\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 761125\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = preprocessing.grouping_dataset(tokenized_datasets,chunk_size)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lm_dataset.pkl\",\"wb\") as fichier:\n",
    "       pickle.dump(lm_datasets,fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 3681534\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 761125\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"lm_dataset.pkl\",\"rb\") as fichier:\n",
    "       lm_datasets=pickle.load(fichier)\n",
    "\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = preprocessing.data_collector_masking(tokenizer,0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laurinemeier/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.67 GiB of which 28.50 MiB is free. Process 17067 has 11.30 GiB memory in use. Process 27687 has 11.29 GiB memory in use. Including non-PyTorch memory, this process has 690.00 MiB memory in use. Of the allocated memory 402.38 MiB is allocated by PyTorch, and 27.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lm_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size)\n\u001b[1;32m      6\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinetuning_hugging\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mcreate_trainer(model,model_name,batch_size,logging_steps,train_dataset\u001b[38;5;241m=\u001b[39mlm_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],eval_dataset\u001b[38;5;241m=\u001b[39mlm_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],data_collator\u001b[38;5;241m=\u001b[39mdata_collator,tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m~/swerick/preprocessing.py:79\u001b[0m, in \u001b[0;36mcreate_trainer\u001b[0;34m(model, model_name, batch_size, logging_steps, learning_rate, decay, train_dataset, eval_dataset, data_collator, tokenizer, push_hub, num_epochs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_trainer\u001b[39m(model,model_name,batch_size,logging_steps,learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,train_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,data_collator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,push_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     60\u001b[0m     training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     61\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-finetuned-imdb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     62\u001b[0m     resume_from_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39mnum_epochs\n\u001b[1;32m     77\u001b[0m )\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  Trainer(\n\u001b[1;32m     80\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     81\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     82\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m     83\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39meval_dataset,\n\u001b[1;32m     84\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     85\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     86\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:495\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[1;32m    494\u001b[0m ):\n\u001b[0;32m--> 495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_model_to_device(model, args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:736\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 736\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:2576\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2572\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2573\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2575\u001b[0m         )\n\u001b[0;32m-> 2576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 23.67 GiB of which 28.50 MiB is free. Process 17067 has 11.30 GiB memory in use. Process 27687 has 11.29 GiB memory in use. Including non-PyTorch memory, this process has 690.00 MiB memory in use. Of the allocated memory 402.38 MiB is allocated by PyTorch, and 27.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs=100\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(lm_datasets[\"train\"]) // batch_size\n",
    "print(len(lm_datasets[\"train\"]) // batch_size)\n",
    "model_name = \"finetuning_hugging\"\n",
    "\n",
    "trainer = preprocessing.create_trainer(model,model_name,batch_size,logging_steps,train_dataset=lm_datasets[\"train\"],eval_dataset=lm_datasets[\"test\"],data_collator=data_collator,tokenizer=tokenizer,num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9d8d117d274ffc8fe119dd6fe428de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.667418479919434, 'eval_runtime': 1311.0834, 'eval_samples_per_second': 804.637, 'eval_steps_per_second': 12.573}\n",
      ">>> Perplexity: 5810.48\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2515404713453cafa42b7acbd7d073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6484600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5597, 'grad_norm': 3.7292888164520264, 'learning_rate': 1.980007710575826e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997d0ed21dba43c1a9bc7a30c3fdf8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1449333429336548, 'eval_runtime': 1220.5197, 'eval_samples_per_second': 864.342, 'eval_steps_per_second': 13.506, 'epoch': 1.0}\n",
      "{'loss': 1.1813, 'grad_norm': 3.9292654991149902, 'learning_rate': 1.9600144958825527e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9b394b878d42779ffc5deff69728a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0173040628433228, 'eval_runtime': 1220.1273, 'eval_samples_per_second': 864.62, 'eval_steps_per_second': 13.51, 'epoch': 2.0}\n",
      "{'loss': 1.0813, 'grad_norm': 3.271228313446045, 'learning_rate': 1.9400225148814117e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2e27e8b2dd41cabeebed60d47a87c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9538872838020325, 'eval_runtime': 1222.2651, 'eval_samples_per_second': 863.107, 'eval_steps_per_second': 13.486, 'epoch': 3.0}\n",
      "{'loss': 1.0251, 'grad_norm': 3.1362099647521973, 'learning_rate': 1.9200299170342043e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2eb0ada0f04c09a2072f4175031fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.914271354675293, 'eval_runtime': 1222.239, 'eval_samples_per_second': 863.126, 'eval_steps_per_second': 13.487, 'epoch': 4.0}\n",
      "{'loss': 0.9872, 'grad_norm': 3.4082911014556885, 'learning_rate': 1.9000370107639642e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7846069214e34b61a5b3cb0ffe261a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1781\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1782\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1783\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1784\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1785\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2213\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2217\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2577\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2575\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2577\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys_for_eval)\n\u001b[1;32m   2578\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2580\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3365\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3362\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3364\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3365\u001b[0m output \u001b[38;5;241m=\u001b[39m eval_loop(\n\u001b[1;32m   3366\u001b[0m     eval_dataloader,\n\u001b[1;32m   3367\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3368\u001b[0m     \u001b[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;00m\n\u001b[1;32m   3369\u001b[0m     \u001b[38;5;66;03m# self.args.prediction_loss_only\u001b[39;00m\n\u001b[1;32m   3370\u001b[0m     prediction_loss_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3371\u001b[0m     ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys,\n\u001b[1;32m   3372\u001b[0m     metric_key_prefix\u001b[38;5;241m=\u001b[39mmetric_key_prefix,\n\u001b[1;32m   3373\u001b[0m )\n\u001b[1;32m   3375\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:3544\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3542\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3543\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 3544\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m   3545\u001b[0m     \u001b[38;5;66;03m# Update the observed num examples\u001b[39;00m\n\u001b[1;32m   3546\u001b[0m     observed_batch_size \u001b[38;5;241m=\u001b[39m find_batch_size(inputs)\n\u001b[1;32m   3547\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observed_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/accelerate/data_loader.py:462\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 462\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:2814\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2814\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(keys)\n\u001b[1;32m   2815\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:2810\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(key)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:2794\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2792\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2793\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2794\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[1;32m   2795\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2796\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2797\u001b[0m )\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/formatting/formatting.py:586\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;66;03m# Query the main table\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 586\u001b[0m     pa_subtable \u001b[38;5;241m=\u001b[39m _query_table(table, key)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    588\u001b[0m     pa_subtable \u001b[38;5;241m=\u001b[39m _query_table_with_indices_mapping(table, key, indices\u001b[38;5;241m=\u001b[39mindices)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/formatting/formatting.py:100\u001b[0m, in \u001b[0;36m_query_table\u001b[0;34m(table, key)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39mslice(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# don't use pyarrow.Table.take even for pyarrow >=1.0 (see https://issues.apache.org/jira/browse/ARROW-9773)\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39mfast_gather(key \u001b[38;5;241m%\u001b[39m table\u001b[38;5;241m.\u001b[39mnum_rows)\n\u001b[1;32m    102\u001b[0m _raise_bad_key_type(key)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/table.py:122\u001b[0m, in \u001b[0;36mIndexedTableMixin.fast_gather\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndices must be non-empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m batch_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offsets, indices, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_batches(\n\u001b[1;32m    123\u001b[0m     [\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batches[batch_idx]\u001b[38;5;241m.\u001b[39mslice(i \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offsets[batch_idx], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_indices, indices)\n\u001b[1;32m    126\u001b[0m     ],\n\u001b[1;32m    127\u001b[0m     schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema,\n\u001b[1;32m    128\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = \"finetuning_hugging.pth\"\n",
    "#model.save_pretrained(\"finetuning_trainer_total\")\n",
    "#tokenizer.save_pretrained(\"finetuning_trainer_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the training and validation losses,\n",
    "print(type(trainer.state.log_history))\n",
    "print(len(trainer.state.log_history))\n",
    "train_losses=[]\n",
    "test_losses=[]\n",
    "for i in range(len(trainer.state.log_history)//2):\n",
    "   train_losses.append(trainer.state.log_history[2*i][\"loss\"])\n",
    "   test_losses.append(trainer.state.log_history[2*i+1][\"eva_loss\"])\n",
    "#eval_losses = trainer.state.log_history[\\\"eval_loss\\\"]\n",
    "\n",
    "#print(train_losses)\n",
    "\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Eval Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1363130699.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    # pickle.dump({'losses_train': train_losses, 'losses_test': test_losses}, f)\u001b[0m\n\u001b[0m                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "file_name = \"losses_hugging.pkl\"\n",
    "with open(file_name, 'wb') as f:\n",
    "   # pickle.dump({'losses_train': train_losses, 'losses_test': test_losses}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
