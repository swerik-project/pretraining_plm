{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoModelForSequenceClassification,AutoTokenizer\n",
    "import torch\n",
    "from datasets import load_dataset,concatenate_datasets\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing\n",
    "import argparse\n",
    "import preprocessing\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at KBLab/bert-base-swedish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"KBLab/bert-base-swedish-cased\"\n",
    "model =  AutoModelForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at finetuning_hugging_python-finetuned-imdb/checkpoint-920384 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_finetuned = AutoModelForSequenceClassification.from_pretrained(\"finetuning_hugging_python-finetuned-imdb/checkpoint-920384\")\n",
    "model_finetuned=model_finetuned.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer= AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_NaN(subset,example):\n",
    "    return example[subset] is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset(dataset,nb_obs):\n",
    "    total_sample=len(dataset)\n",
    "    subset_size=nb_obs\n",
    "    num_subset = total_sample//subset_size +(0 if total_sample%subset_size==0 else 1)\n",
    "    sub_datasets=[]\n",
    "    for i in range(num_subset):\n",
    "        start_index=i*subset_size\n",
    "        end_index = min((i+1)*subset_size,total_sample)\n",
    "        sub_dataset=dataset.select(indices=range(start_index,end_index))\n",
    "        sub_datasets.append(sub_dataset)\n",
    "    return sub_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"Note\"],padding=True, truncation=True,max_length=512)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    loss, accuracy = 0.0, []\n",
    "    model.eval()\n",
    "    for batch in tqdm(loader, total=len(loader)):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        input_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        output = model(input_ids,\n",
    "            token_type_ids=None, \n",
    "            attention_mask=input_mask, \n",
    "            labels=labels)\n",
    "        loss += output.loss.item()\n",
    "        preds_batch = torch.argmax(output.logits, axis=1)\n",
    "        batch_acc = torch.mean((preds_batch == labels).float())\n",
    "        accuracy.append(batch_acc)\n",
    "        \n",
    "    accuracy = torch.mean(torch.tensor(accuracy))\n",
    "    return loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['protocole', 'Note', 'id', 'party', 'gender'],\n",
      "        num_rows: 3378877\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['protocole', 'Note', 'id', 'party', 'gender'],\n",
      "        num_rows: 725974\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_files = {\"train\": \"swerick_data_party_train.pkl\", \"test\": \"swerick_data_party_test.pkl\"}\n",
    "party_dataset = load_dataset(\"pandas\",data_files=data_files)\n",
    "print(party_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    valid: Dataset({\n",
      "        features: ['protocole', 'Note', 'id', 'party', 'gender'],\n",
      "        num_rows: 725974\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_files = {\"valid\": \"swerick_data_party_valid.pkl\"}\n",
    "party_valid_dataset = load_dataset(\"pandas\",data_files=data_files)\n",
    "print(party_valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a list of Dataset objects or a list of IterableDataset objects, but element at position 0 is a dict.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m whole_party_dataset \u001b[38;5;241m=\u001b[39m concatenate_datasets(party_valid_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m],party_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],party_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/datasets/combine.py:201\u001b[0m, in \u001b[0;36mconcatenate_datasets\u001b[0;34m(dsets, info, split, axis)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a list of Dataset objects or a list of IterableDataset objects, but element at position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis an empty dataset dictionary.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m             )\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    198\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset at position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has at least one split: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease pick one to interleave with the other datasets, for example: dataset[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataset))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m         )\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a list of Dataset objects or a list of IterableDataset objects, but element at position \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dataset)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    205\u001b[0m     dataset_type, other_type \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    206\u001b[0m         (Dataset, IterableDataset) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, Dataset) \u001b[38;5;28;01melse\u001b[39;00m (IterableDataset, Dataset)\n\u001b[1;32m    207\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a list of Dataset objects or a list of IterableDataset objects, but element at position 0 is a dict."
     ]
    }
   ],
   "source": [
    "whole_party_dataset = concatenate_datasets(party_valid_dataset[\"valid\"],party_dataset[\"train\"],party_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_dataset[\"train\"]=party_dataset[\"train\"].filter(lambda x : filter_NaN(\"party\",x))\n",
    "party_dataset[\"test\"]=party_dataset[\"test\"].filter(lambda x : filter_NaN(\"party\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_valid_dataset[\"valid\"]=party_valid_dataset[\"valid\"].filter(lambda x : filter_NaN(\"party\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\"vänstern\"', 1: 'Andra kammarens center', 2: 'Andra kammarens frihandelsparti', 3: 'Bondeförbundet', 4: 'Centern (partigrupp 1873-1882)', 5: 'Centern (partigrupp 1885-1887)', 6: 'Centerpartiet', 7: 'Det förenade högerpartiet', 8: 'Ehrenheimska partiet', 9: 'Folkpartiet', 10: 'Folkpartiet (1895–1900)', 11: 'Friesenska diskussionsklubben', 12: 'Frihandelsvänliga centern', 13: 'Frisinnade folkpartiet', 14: 'Frisinnade försvarsvänner', 15: 'Frisinnade landsföreningen', 16: 'Första kammarens konservativa grupp', 17: 'Första kammarens ministeriella grupp', 18: 'Första kammarens minoritetsparti', 19: 'Första kammarens moderata parti', 20: 'Första kammarens nationella parti', 21: 'Första kammarens protektionistiska parti', 22: 'Gamla lantmannapartiet', 23: 'Högerns riksdagsgrupp', 24: 'Högerpartiet', 25: 'Högerpartiet de konservativa', 26: 'Jordbrukarnas fria grupp', 27: 'Junkerpartiet', 28: 'Kilbomspartiet', 29: 'Kommunistiska partiet', 30: 'Kristdemokraterna', 31: 'Lantmanna- och borgarepartiet inom andrakammaren', 32: 'Lantmannapartiet', 33: 'Lantmannapartiets filial', 34: 'Liberala riksdagspartiet', 35: 'Liberala samlingspartiet', 36: 'Liberalerna', 37: 'Medborgerlig samling (1964–1968)', 38: 'Miljöpartiet', 39: 'Moderaterna', 40: 'Nationella framstegspartiet', 41: 'Ny demokrati', 42: 'Nya centern (partigrupp 1883-1887)', 43: 'Nya lantmannapartiet', 44: 'Nyliberala partiet', 45: 'Skånska partiet', 46: 'Socialdemokraterna', 47: 'Socialdemokratiska vänstergruppen', 48: 'Socialistiska partiet', 49: 'Stockholmsbänken', 50: 'Sverigedemokraterna', 51: 'Sveriges kommunistiska parti', 52: 'Vänsterpartiet', 53: 'borgmästarepartiet', 54: 'frihandelsvänlig vilde', 55: 'frisinnad vilde', 56: 'högervilde', 57: 'ministeriella partiet', 58: 'partilös', 59: 'politisk vilde', 60: 'vänstervilde'}\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(party_dataset[\"train\"][\"party\"])\n",
    "label_names = label_encoder.classes_\n",
    "label_dict={ i : label_names[i] for i in  range(len(label_names))}\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"vänstern\"' 'Andra kammarens center' 'Andra kammarens frihandelsparti'\n",
      " 'Bondeförbundet' 'Centern (partigrupp 1873-1882)'\n",
      " 'Centern (partigrupp 1885-1887)' 'Centerpartiet'\n",
      " 'Det förenade högerpartiet' 'Ehrenheimska partiet' 'Folkpartiet'\n",
      " 'Folkpartiet (1895–1900)' 'Friesenska diskussionsklubben'\n",
      " 'Frihandelsvänliga centern' 'Frisinnade folkpartiet'\n",
      " 'Frisinnade försvarsvänner' 'Frisinnade landsföreningen'\n",
      " 'Första kammarens konservativa grupp'\n",
      " 'Första kammarens ministeriella grupp' 'Första kammarens minoritetsparti'\n",
      " 'Första kammarens moderata parti' 'Första kammarens nationella parti'\n",
      " 'Första kammarens protektionistiska parti' 'Gamla lantmannapartiet'\n",
      " 'Högerns riksdagsgrupp' 'Högerpartiet' 'Högerpartiet de konservativa'\n",
      " 'Jordbrukarnas fria grupp' 'Junkerpartiet' 'Kilbomspartiet'\n",
      " 'Kommunistiska partiet' 'Kristdemokraterna'\n",
      " 'Lantmanna- och borgarepartiet inom andrakammaren' 'Lantmannapartiet'\n",
      " 'Lantmannapartiets filial' 'Liberala riksdagspartiet'\n",
      " 'Liberala samlingspartiet' 'Liberalerna'\n",
      " 'Medborgerlig samling (1964–1968)' 'Miljöpartiet' 'Moderaterna'\n",
      " 'Nationella framstegspartiet' 'Ny demokrati'\n",
      " 'Nya centern (partigrupp 1883-1887)' 'Nya lantmannapartiet'\n",
      " 'Nyliberala partiet' 'Skånska partiet' 'Socialdemokraterna'\n",
      " 'Socialdemokratiska vänstergruppen' 'Socialistiska partiet'\n",
      " 'Stockholmsbänken' 'Sverigedemokraterna' 'Sveriges kommunistiska parti'\n",
      " 'Vänsterpartiet' 'borgmästarepartiet' 'frihandelsvänlig vilde'\n",
      " 'frisinnad vilde' 'högervilde' 'ministeriella partiet' 'partilös'\n",
      " 'politisk vilde' 'vänstervilde']\n"
     ]
    }
   ],
   "source": [
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labels.pkl\", \"wb\") as fp:   \n",
    "   pickle.dump(label_names, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"vänstern\"', 'Andra kammarens center', 'Andra kammarens frihandelsparti', 'Bondeförbundet', 'Centern (partigrupp 1873-1882)', 'Centern (partigrupp 1885-1887)', 'Centerpartiet', 'Det förenade högerpartiet', 'Ehrenheimska partiet', 'Folkpartiet', 'Folkpartiet (1895–1900)', 'Friesenska diskussionsklubben', 'Frihandelsvänliga centern', 'Frisinnade folkpartiet', 'Frisinnade försvarsvänner', 'Frisinnade landsföreningen', 'Första kammarens konservativa grupp', 'Första kammarens ministeriella grupp', 'Första kammarens minoritetsparti', 'Första kammarens moderata parti', 'Första kammarens nationella parti', 'Första kammarens protektionistiska parti', 'Gamla lantmannapartiet', 'Högerns riksdagsgrupp', 'Högerpartiet', 'Högerpartiet de konservativa', 'Jordbrukarnas fria grupp', 'Junkerpartiet', 'Kilbomspartiet', 'Kommunistiska partiet', 'Kristdemokraterna', 'Lantmanna- och borgarepartiet inom andrakammaren', 'Lantmannapartiet', 'Lantmannapartiets filial', 'Liberala riksdagspartiet', 'Liberala samlingspartiet', 'Liberalerna', 'Medborgerlig samling (1964–1968)', 'Miljöpartiet', 'Moderaterna', 'Nationella framstegspartiet', 'Ny demokrati', 'Nya centern (partigrupp 1883-1887)', 'Nya lantmannapartiet', 'Nyliberala partiet', 'Skånska partiet', 'Socialdemokraterna', 'Socialdemokratiska vänstergruppen', 'Socialistiska partiet', 'Stockholmsbänken', 'Sverigedemokraterna', 'Sveriges kommunistiska parti', 'Vänsterpartiet', 'borgmästarepartiet', 'frihandelsvänlig vilde', 'frisinnad vilde', 'högervilde', 'ministeriella partiet', 'partilös', 'politisk vilde', 'vänstervilde']\n"
     ]
    }
   ],
   "source": [
    "with open(\"labels.pkl\",\"rb\") as f :\n",
    "    label_names=pickle.load(f)\n",
    "\n",
    "print(label_names.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd66216ff8b7498b82f317f5fa70a787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3167750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb7d5b1dc7343d29302a461e6bb589a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/676215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "party_dataset[\"train\"]=party_dataset[\"train\"].map(lambda example :{\"party_labels\" : label_encoder.transform([example[\"party\"]])[0]})\n",
    "party_dataset[\"test\"]=party_dataset[\"test\"].map(lambda example :{\"party_labels\" : label_encoder.transform([example[\"party\"]])[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b08effd0de948f9adad4a48eea250c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/676215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "party_valid_dataset[\"valid\"]=party_valid_dataset[\"valid\"].map(lambda example :{\"party_labels\" : label_encoder.transform([example[\"party\"]])[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_party_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_train_datasets = subset(party_dataset[\"train\"],1000)\n",
    "party_test_datasets = subset(party_dataset[\"test\"],10000)\n",
    "party_valid_datasets = subset(party_valid_dataset[\"valid\"],10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = party_train_datasets[0]\n",
    "test_set = party_test_datasets[0]\n",
    "valid_set = party_valid_datasets[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['protocole', 'Note', 'id', 'party', 'gender'],\n",
      "    num_rows: 1000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['protocole', 'Note', 'id', 'party', 'gender'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['protocole', 'Note', 'id', 'party', 'gender'],\n",
      "    num_rows: 10000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_set)\n",
    "print(test_set)\n",
    "print(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_dataset = concatenate_datasets([train_set,test_set,valid_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf0c5d568d14d3187098a196fc89053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44069f30059b48a69af1fdc14a547fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbc8a737ea74bd9b4f5d799b1562c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['protocole', 'Note', 'id', 'party', 'gender', 'party_labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_datasets = train_set.map(tokenize_function,batched=True )\n",
    "tokenized_test_datasets = test_set.map(tokenize_function,batched=True )\n",
    "tokenized_valid_datasets = valid_set.map(tokenize_function,batched=True )\n",
    "tokenized_train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_datasets=tokenized_train_datasets.remove_columns([\"protocole\",\"id\",\"party\",\"gender\",\"Note\"])\n",
    "tokenized_test_datasets=tokenized_test_datasets.remove_columns([\"protocole\",\"id\",\"party\",\"gender\",\"Note\"])\n",
    "tokenized_valid_datasets=tokenized_valid_datasets.remove_columns([\"protocole\",\"id\",\"party\",\"gender\",\"Note\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_datasets=tokenized_train_datasets.rename_column(\"party_labels\",\"labels\")\n",
    "tokenized_test_datasets=tokenized_test_datasets.rename_column(\"party_labels\",\"labels\")\n",
    "tokenized_valid_datasets=tokenized_valid_datasets.rename_column(\"party_labels\",\"labels\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_datasets.set_format(type=\"torch\",columns=[\"input_ids\",\"labels\",\"attention_mask\"])\n",
    "tokenized_test_datasets.set_format(type=\"torch\",columns=[\"input_ids\",\"labels\",\"attention_mask\"])\n",
    "tokenized_valid_datasets.set_format(type=\"torch\",columns=[\"input_ids\",\"labels\",\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers=4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        tokenized_train_datasets,\n",
    "        shuffle=True,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "        tokenized_valid_datasets,\n",
    "        shuffle=False,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "\n",
    "# Not used atm\n",
    "test_loader = DataLoader(\n",
    "        tokenized_test_datasets,\n",
    "        shuffle=False,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at KBLab/bert-base-swedish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "n_epochs =10\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_checkpoint,\n",
    "        num_labels=len(label_dict),\n",
    "        id2label=label_dict).to(\"cpu\")\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5)\n",
    "num_training_steps = len(train_loader) * n_epochs\n",
    "num_warmup_steps = num_training_steps // 10\n",
    "\n",
    "# Linear warmup and step decay\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = num_warmup_steps,\n",
    "    num_training_steps = num_training_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 starts!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e676a3017ebb4c0aa370cd38b4da83a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b8de45011b4fdca04cf6f15bc8ac5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m valid_loss, valid_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, valid_loader)\n\u001b[1;32m     31\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     32\u001b[0m valid_losses\u001b[38;5;241m.\u001b[39mappend(valid_loss)\n",
      "Cell \u001b[0;32mIn[48], line 5\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(loader, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(loader)):\n\u001b[0;32m----> 5\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      6\u001b[0m     input_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      7\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "device=\"cpu\"\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch} starts!\")\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader, total=len(train_loader)):\n",
    "        model.zero_grad()   \n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        input_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        output = model(input_ids,\n",
    "                token_type_ids=None, \n",
    "                attention_mask=input_mask, \n",
    "                labels=labels)\n",
    "        loss = output.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Evaluation\n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    train_loss_avg = train_loss * batch_size / len(train_loader)\n",
    "    valid_loss_avg = valid_loss * batch_size / len(valid_loader)\n",
    "\n",
    "    print(f'Training Loss: {train_loss_avg:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss_avg:.3f}')\n",
    "    print(f'Validation accuracy: {valid_accuracy}')\n",
    "\n",
    "    # Store best model\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        print(\"Best validation loss so far\")\n",
    "        best_valid_loss = valid_loss\n",
    " \n",
    "    else:\n",
    "            print(\"Not the best validation loss so far\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58640bf698e843c3aabdd833e9d43487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "valid_loss, valid_accuracy = evaluate(model, valid_loader)\n",
    "\n",
    "train_losses.append(train_loss)\n",
    "valid_losses.append(valid_loss)\n",
    "\n",
    "train_loss_avg = train_loss * batch_size / len(train_loader)\n",
    "valid_loss_avg = valid_loss * batch_size / len(valid_loader)\n",
    "\n",
    "print(f'Training Loss: {train_loss_avg:.3f}')\n",
    "print(f'Validation Loss: {valid_loss_avg:.3f}')\n",
    "print(f'Validation accuracy: {valid_accuracy}')\n",
    "\n",
    "# Store best model\n",
    "\n",
    "if valid_loss < best_valid_loss:\n",
    "    print(\"Best validation loss so far\")\n",
    "    best_valid_loss = valid_loss\n",
    "else:\n",
    "        print(\"Not the best validation loss so far\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_pickle(\"swerick_data_party_train.pkl\")\n",
    "df = df.rename(columns={\"Note\":\"content\",\"party\" : \"tag\"})\n",
    "df.to_csv(\"swerick_data_party_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['party']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12983/2349304386.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"swerick_data_party_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"party\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6414\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6415\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6416\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6417\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6418\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6419\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ['party']"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"swerick_data_party_train.csv\")\n",
    "df =df.dropna(subset=\"tag\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.dropna(subset=\"tag\")\n",
    "df.to_csv(\"swerick_data_party_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=test_set.to_pandas()\n",
    "df = df.rename(columns={\"Note\":\"content\",\"party\" : \"tag\"})\n",
    "df.to_csv(\"swerick_subsetdata_party_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = sorted(list(set(df[\"tag\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\"vänstern\"', 'Andra kammarens center',\n",
       "       'Andra kammarens frihandelsparti', 'Bondeförbundet',\n",
       "       'Centern (partigrupp 1873-1882)', 'Centern (partigrupp 1885-1887)',\n",
       "       'Centerpartiet', 'Det förenade högerpartiet',\n",
       "       'Ehrenheimska partiet', 'Folkpartiet', 'Folkpartiet (1895–1900)',\n",
       "       'Friesenska diskussionsklubben', 'Frihandelsvänliga centern',\n",
       "       'Frisinnade folkpartiet', 'Frisinnade försvarsvänner',\n",
       "       'Frisinnade landsföreningen',\n",
       "       'Första kammarens konservativa grupp',\n",
       "       'Första kammarens ministeriella grupp',\n",
       "       'Första kammarens minoritetsparti',\n",
       "       'Första kammarens moderata parti',\n",
       "       'Första kammarens nationella parti',\n",
       "       'Första kammarens protektionistiska parti',\n",
       "       'Gamla lantmannapartiet', 'Högerns riksdagsgrupp', 'Högerpartiet',\n",
       "       'Högerpartiet de konservativa', 'Jordbrukarnas fria grupp',\n",
       "       'Junkerpartiet', 'Kilbomspartiet', 'Kommunistiska partiet',\n",
       "       'Kristdemokraterna',\n",
       "       'Lantmanna- och borgarepartiet inom andrakammaren',\n",
       "       'Lantmannapartiet', 'Lantmannapartiets filial',\n",
       "       'Liberala riksdagspartiet', 'Liberala samlingspartiet',\n",
       "       'Liberalerna', 'Medborgerlig samling (1964–1968)', 'Miljöpartiet',\n",
       "       'Moderaterna', 'Nationella framstegspartiet', 'Ny demokrati',\n",
       "       'Nya centern (partigrupp 1883-1887)', 'Nya lantmannapartiet',\n",
       "       'Nyliberala partiet', 'Skånska partiet', 'Socialdemokraterna',\n",
       "       'Socialdemokratiska vänstergruppen', 'Socialistiska partiet',\n",
       "       'Stockholmsbänken', 'Sverigedemokraterna',\n",
       "       'Sveriges kommunistiska parti', 'Vänsterpartiet',\n",
       "       'borgmästarepartiet', 'frihandelsvänlig vilde', 'frisinnad vilde',\n",
       "       'högervilde', 'ministeriella partiet', 'partilös',\n",
       "       'politisk vilde', 'vänstervilde'], dtype='<U48')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"vänstern\"\" \"Andra kammarens center\" \"Andra kammarens frihandelsparti\" \"Bondeförbundet\" \"Centern (partigrupp 1873-1882)\" \"Centern (partigrupp 1885-1887)\" \"Centerpartiet\" \"Det förenade högerpartiet\" \"Ehrenheimska partiet\" \"Folkpartiet\" \"Folkpartiet (1895–1900)\" \"Friesenska diskussionsklubben\" \"Frihandelsvänliga centern\" \"Frisinnade folkpartiet\" \"Frisinnade försvarsvänner\" \"Frisinnade landsföreningen\" \"Första kammarens konservativa grupp\" \"Första kammarens ministeriella grupp\" \"Första kammarens minoritetsparti\" \"Första kammarens moderata parti\" \"Första kammarens nationella parti\" \"Första kammarens protektionistiska parti\" \"Gamla lantmannapartiet\" \"Högerns riksdagsgrupp\" \"Högerpartiet\" \"Högerpartiet de konservativa\" \"Jordbrukarnas fria grupp\" \"Junkerpartiet\" \"Kilbomspartiet\" \"Kommunistiska partiet\" \"Kristdemokraterna\" \"Lantmanna- och borgarepartiet inom andrakammaren\" \"Lantmannapartiet\" \"Lantmannapartiets filial\" \"Liberala riksdagspartiet\" \"Liberala samlingspartiet\" \"Liberalerna\" \"Medborgerlig samling (1964–1968)\" \"Miljöpartiet\" \"Moderaterna\" \"Nationella framstegspartiet\" \"Ny demokrati\" \"Nya centern (partigrupp 1883-1887)\" \"Nya lantmannapartiet\" \"Nyliberala partiet\" \"Skånska partiet\" \"Socialdemokraterna\" \"Socialdemokratiska vänstergruppen\" \"Socialistiska partiet\" \"Stockholmsbänken\" \"Sverigedemokraterna\" \"Sveriges kommunistiska parti\" \"Vänsterpartiet\" \"borgmästarepartiet\" \"frihandelsvänlig vilde\" \"frisinnad vilde\" \"högervilde\" \"ministeriella partiet\" \"partilös\" \"politisk vilde\" \"vänstervilde\"'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir la liste de noms de libellés en une chaîne séparée par des espaces avec chaque nom entouré de guillemets simples\n",
    "label_names_str = \" \".join([f'\"{name}\"' for name in label_names.tolist()])\n",
    "\n",
    "label_names_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vänstern', 'Andra kammarens center', 'Andra kammarens frihandelsparti', 'Bondeförbundet', 'Centern (partigrupp 1873-1882)', 'Centern (partigrupp 1885-1887)', 'Centerpartiet', 'Det förenade högerpartiet', 'Ehrenheimska partiet', 'Folkpartiet', 'Folkpartiet (1895–1900)', 'Friesenska diskussionsklubben', 'Frihandelsvänliga centern', 'Frisinnade folkpartiet', 'Frisinnade försvarsvänner', 'Frisinnade landsföreningen', 'Första kammarens konservativa grupp', 'Första kammarens ministeriella grupp', 'Första kammarens minoritetsparti', 'Första kammarens moderata parti', 'Första kammarens nationella parti', 'Första kammarens protektionistiska parti', 'Gamla lantmannapartiet', 'Högerns riksdagsgrupp', 'Högerpartiet', 'Högerpartiet de konservativa', 'Jordbrukarnas fria grupp', 'Junkerpartiet', 'Kilbomspartiet', 'Kommunistiska partiet', 'Kristdemokraterna', 'Lantmanna- och borgarepartiet inom andrakammaren', 'Lantmannapartiet', 'Lantmannapartiets filial', 'Liberala riksdagspartiet', 'Liberala samlingspartiet', 'Liberalerna', 'Medborgerlig samling (1964–1968)', 'Miljöpartiet', 'Moderaterna', 'Nationella framstegspartiet', 'Ny demokrati', 'Nya centern (partigrupp 1883-1887)', 'Nya lantmannapartiet', 'Nyliberala partiet', 'Skånska partiet', 'Socialdemokraterna', 'Socialdemokratiska vänstergruppen', 'Socialistiska partiet', 'Stockholmsbänken', 'Sverigedemokraterna', 'Sveriges kommunistiska parti', 'Vänsterpartiet', 'borgmästarepartiet', 'frihandelsvänlig vilde', 'frisinnad vilde', 'högervilde', 'ministeriella partiet', 'partilös', 'politisk vilde', 'vänstervilde']\n",
      "{0: 'vänstern', 1: 'Andra kammarens center', 2: 'Andra kammarens frihandelsparti', 3: 'Bondeförbundet', 4: 'Centern (partigrupp 1873-1882)', 5: 'Centern (partigrupp 1885-1887)', 6: 'Centerpartiet', 7: 'Det förenade högerpartiet', 8: 'Ehrenheimska partiet', 9: 'Folkpartiet', 10: 'Folkpartiet (1895–1900)', 11: 'Friesenska diskussionsklubben', 12: 'Frihandelsvänliga centern', 13: 'Frisinnade folkpartiet', 14: 'Frisinnade försvarsvänner', 15: 'Frisinnade landsföreningen', 16: 'Första kammarens konservativa grupp', 17: 'Första kammarens ministeriella grupp', 18: 'Första kammarens minoritetsparti', 19: 'Första kammarens moderata parti', 20: 'Första kammarens nationella parti', 21: 'Första kammarens protektionistiska parti', 22: 'Gamla lantmannapartiet', 23: 'Högerns riksdagsgrupp', 24: 'Högerpartiet', 25: 'Högerpartiet de konservativa', 26: 'Jordbrukarnas fria grupp', 27: 'Junkerpartiet', 28: 'Kilbomspartiet', 29: 'Kommunistiska partiet', 30: 'Kristdemokraterna', 31: 'Lantmanna- och borgarepartiet inom andrakammaren', 32: 'Lantmannapartiet', 33: 'Lantmannapartiets filial', 34: 'Liberala riksdagspartiet', 35: 'Liberala samlingspartiet', 36: 'Liberalerna', 37: 'Medborgerlig samling (1964–1968)', 38: 'Miljöpartiet', 39: 'Moderaterna', 40: 'Nationella framstegspartiet', 41: 'Ny demokrati', 42: 'Nya centern (partigrupp 1883-1887)', 43: 'Nya lantmannapartiet', 44: 'Nyliberala partiet', 45: 'Skånska partiet', 46: 'Socialdemokraterna', 47: 'Socialdemokratiska vänstergruppen', 48: 'Socialistiska partiet', 49: 'Stockholmsbänken', 50: 'Sverigedemokraterna', 51: 'Sveriges kommunistiska parti', 52: 'Vänsterpartiet', 53: 'borgmästarepartiet', 54: 'frihandelsvänlig vilde', 55: 'frisinnad vilde', 56: 'högervilde', 57: 'ministeriella partiet', 58: 'partilös', 59: 'politisk vilde', 60: 'vänstervilde'}\n",
      "61\n",
      "\u001b[32m17:05:14 [INFO] \u001b[37m(train-bert)\u001b[0m: Load and save tokenizer...\u001b[0m\n",
      "\u001b[32m17:05:15 [INFO] \u001b[37m(train-bert)\u001b[0m: Preprocess datasets...\u001b[0m\n",
      "\u001b[32m17:05:15 [INFO] \u001b[37m(train-bert)\u001b[0m: Labels: tensor([57, 57, 57, 57, 57, 32, 32, 32, 33, 32, 32, 57, 32, 32, 32, 32, 57, 32,\n",
      "        21, 57, 57, 57, 43, 57, 57, 57, 57, 57, 32, 32, 32, 57, 22, 32, 57, 32,\n",
      "        32, 32, 57, 57, 57, 57, 32, 32, 57, 57, 32, 22, 32, 57, 57, 57, 57, 57,\n",
      "        57, 32, 43, 57, 32, 32, 57, 32, 57, 32, 57, 57, 57, 32, 33, 57, 57, 57,\n",
      "        22, 32, 57, 32, 32, 57, 32, 32, 57, 22, 57, 57, 32, 32, 57, 32, 57, 57,\n",
      "        22, 32, 44, 32, 33, 57, 57, 57, 57, 32, 57, 57, 57, 32, 32, 57, 57, 57,\n",
      "        57, 57, 32, 32, 32, 57, 32, 33, 32, 32, 43, 57, 33, 57, 32, 32, 57, 57,\n",
      "        57, 32, 32, 57, 57, 32, 32, 57, 57, 32, 43, 57, 32, 57, 57, 57, 57, 57,\n",
      "        57, 57, 57, 57, 33, 57, 33, 57, 57, 32, 32, 57, 32, 57, 32, 57, 57, 32,\n",
      "        32, 57, 32, 44, 57, 57, 57, 32, 57, 32, 57, 33, 32, 22, 57, 57, 32, 32,\n",
      "        32, 57, 32, 22, 57, 57, 44, 57, 57, 22, 33, 57, 32, 57, 57, 57, 32, 57,\n",
      "        57, 57, 32, 32, 44, 57, 32, 32, 57, 57, 32, 57, 32, 57, 32, 32, 33, 57,\n",
      "        32, 57, 57, 57, 32, 57, 57, 32, 32, 32, 57, 57, 22, 57, 57, 22, 57, 57,\n",
      "        32, 57, 21, 43, 57, 57, 57, 32, 32, 32, 57, 43, 57, 32, 32, 43, 33, 22,\n",
      "        57, 32, 57, 33, 32, 57, 32, 32, 21, 57, 43, 57, 57, 57, 57, 57, 57, 57,\n",
      "        57, 32, 57, 22, 57, 57, 57,  5, 57, 32, 32, 57, 32, 32, 57, 57, 32, 57,\n",
      "        57, 57, 57, 32, 32, 57, 57, 57, 32, 32, 57, 32, 32, 32, 32, 57, 57, 32,\n",
      "        43, 32, 57, 32, 57, 43, 57, 43, 32, 57, 57, 32, 32, 32, 32, 32, 32, 57,\n",
      "        32, 32, 32, 57, 32, 57, 57, 57, 32, 44, 57, 32, 57, 32, 32, 32, 57, 32,\n",
      "        32, 32, 32, 57, 32, 33, 57, 57, 32, 32, 32, 57, 57, 57, 57, 57, 57, 32,\n",
      "        32, 57, 57, 57, 32, 32, 32, 32, 57, 57, 57, 57, 32, 32, 32, 32, 57, 57,\n",
      "        57, 57, 32, 32, 57, 32, 57, 57, 32, 33, 57, 32, 57, 32, 57, 32, 57, 57,\n",
      "        32, 32, 57, 32, 57, 57, 57, 57, 57, 32, 57, 57, 57, 57, 32, 32, 57, 32,\n",
      "        57, 57, 57, 57, 32, 32, 32, 57, 32, 57, 57, 43, 57, 57, 57, 32, 32, 57,\n",
      "        33, 57, 57, 32, 57, 22, 57, 21, 32, 57, 57, 32, 57, 32, 57, 32, 32, 57,\n",
      "        32,  5, 32, 57, 32, 57, 57, 57, 32, 32, 32, 44, 32, 32, 22, 57, 57, 57,\n",
      "        57, 32, 57, 32, 57, 32, 57, 32, 57, 33, 32, 57, 57, 32, 57, 57, 32, 57,\n",
      "        57, 57, 32, 32, 57, 57, 57, 32, 32, 57, 57, 57, 57, 57, 57, 57, 57, 57,\n",
      "        21, 57, 57, 22, 32, 57, 32, 32, 57, 32, 57, 32, 57, 57, 57, 32, 32, 57,\n",
      "        57, 32, 57, 32, 57, 57, 57, 32, 57, 32, 57, 57, 57, 32, 43, 32, 43, 32,\n",
      "        32, 32, 57, 32, 32, 32, 57, 57, 57, 57, 32, 32, 32, 43, 57, 57, 57, 57,\n",
      "        32, 32, 57, 32, 32, 57, 32, 57, 22, 57, 57, 57, 57, 32, 57, 57, 57, 57,\n",
      "        43, 57, 57, 32, 32, 57, 32, 57, 32, 22, 57, 57, 57, 57, 57, 33, 33, 32,\n",
      "        32, 57, 32, 32, 32, 57, 43, 57, 57, 57, 57, 57, 32, 32, 57, 32, 22, 32,\n",
      "        32, 21, 57, 43, 57, 57, 22, 57, 57, 32, 32, 32, 32, 32, 32, 57, 57, 33,\n",
      "        32, 57, 57, 32, 57, 32, 57, 57, 57, 22, 32, 32, 57, 32, 57, 32, 57, 57,\n",
      "        57, 57, 32, 32, 57, 57, 57, 57, 57, 32, 32, 57, 57, 32, 57, 32, 32, 57,\n",
      "        32, 22, 57, 57, 32, 32, 32, 57, 57, 32, 57, 57, 57, 57, 57, 32, 57, 32,\n",
      "        57, 33, 57, 57, 32, 57, 57, 32, 32, 32, 57, 32, 22, 32, 57, 57, 32, 57,\n",
      "        57, 32, 32, 32, 57, 32, 57, 32, 57, 57, 32, 32, 32, 57, 57, 43, 57, 32,\n",
      "        57, 32, 57, 57, 32, 32, 32, 32, 57, 32, 32, 33, 57, 32, 32, 57, 32, 57,\n",
      "        32, 32, 32,  5, 22, 57, 32, 22, 57, 32, 32, 57, 57, 57, 32, 32, 32, 22,\n",
      "        43, 32, 32, 57, 57, 32, 32, 57, 32, 43, 32, 57, 32, 43, 32, 57, 32, 57,\n",
      "        22, 57, 32, 57, 32, 32, 57, 22, 32, 57, 57, 43, 32, 57, 32, 32, 57, 57,\n",
      "        57, 22, 32, 32, 57, 57, 32, 57, 57, 32, 32, 57, 57, 32, 32, 57, 32, 57,\n",
      "        57, 57, 32, 32, 32, 32, 57, 32, 33, 57, 57, 57, 32, 57, 57, 32, 33, 32,\n",
      "        57, 57, 57, 57, 33, 32, 32, 32, 33, 32, 32, 57, 32, 57, 43, 32, 57, 32,\n",
      "        32, 32, 57, 32, 32, 32, 57, 32, 57, 57, 57, 57, 32, 32, 57, 57, 44, 44,\n",
      "        43, 32, 32, 57, 32, 32, 57, 32, 32, 32, 57, 32, 57, 32, 32, 57, 57, 57,\n",
      "        22, 57, 32, 57, 57, 57, 32, 32, 32, 57, 57, 57, 32, 32, 57, 57, 32, 32,\n",
      "        32, 57, 32, 32, 57, 57, 32, 57, 57, 32, 57, 57, 22, 57, 32, 32, 57, 32,\n",
      "        57, 32, 57, 32, 57, 57, 42, 32, 57, 57, 57, 32, 44, 32, 32, 57, 57, 57,\n",
      "        57, 32, 32, 57, 57, 32, 32, 32, 32, 57, 57, 22, 57, 32, 22, 57, 57, 57,\n",
      "        57, 57, 57, 32, 32, 43, 32, 57, 43, 32, 43, 57, 32, 57, 32, 32, 57, 32,\n",
      "        57, 57, 32, 32, 57, 57, 57, 22, 57, 32, 32, 57, 57, 57, 57, 57, 57, 57,\n",
      "        57, 57, 57, 32, 57, 22, 32, 57, 32, 32])\u001b[0m\n",
      "/home/laurinemeier/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at KBLab/bert-base-swedish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m17:05:16 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 0 starts!\u001b[0m\n",
      "  0%|                                                    | 0/38 [00:00<?, ?it/s]/home/laurinemeier/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "100%|███████████████████████████████████████████| 38/38 [00:12<00:00,  3.10it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  7.90it/s]\n",
      "\u001b[34m17:05:30 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 47.128\u001b[0m\n",
      "\u001b[34m17:05:30 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 28.447\u001b[0m\n",
      "\u001b[34m17:05:30 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.4038461446762085\u001b[0m\n",
      "\u001b[32m17:05:30 [INFO] \u001b[37m(train-bert)\u001b[0m: Best validation loss so far\u001b[0m\n",
      "\u001b[34m17:05:31 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 1 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.33it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  7.90it/s]\n",
      "\u001b[34m17:05:44 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 22.468\u001b[0m\n",
      "\u001b[34m17:05:44 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 22.018\u001b[0m\n",
      "\u001b[34m17:05:44 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.4711538553237915\u001b[0m\n",
      "\u001b[32m17:05:44 [INFO] \u001b[37m(train-bert)\u001b[0m: Best validation loss so far\u001b[0m\n",
      "\u001b[34m17:05:45 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 2 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.35it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.02it/s]\n",
      "\u001b[34m17:05:58 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 19.520\u001b[0m\n",
      "\u001b[34m17:05:58 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 20.844\u001b[0m\n",
      "\u001b[34m17:05:58 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.5288461446762085\u001b[0m\n",
      "\u001b[32m17:05:58 [INFO] \u001b[37m(train-bert)\u001b[0m: Best validation loss so far\u001b[0m\n",
      "\u001b[34m17:05:59 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 3 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.34it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.35it/s]\n",
      "\u001b[34m17:06:12 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 18.452\u001b[0m\n",
      "\u001b[34m17:06:12 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 20.550\u001b[0m\n",
      "\u001b[34m17:06:12 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.48557692766189575\u001b[0m\n",
      "\u001b[32m17:06:12 [INFO] \u001b[37m(train-bert)\u001b[0m: Best validation loss so far\u001b[0m\n",
      "\u001b[34m17:06:14 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 4 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.37it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  7.98it/s]\n",
      "\u001b[34m17:06:27 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 17.561\u001b[0m\n",
      "\u001b[34m17:06:27 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 20.772\u001b[0m\n",
      "\u001b[34m17:06:27 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.48557692766189575\u001b[0m\n",
      "\u001b[32m17:06:27 [INFO] \u001b[37m(train-bert)\u001b[0m: Not the best validation loss so far\u001b[0m\n",
      "\u001b[34m17:06:27 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 5 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.27it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  7.68it/s]\n",
      "\u001b[34m17:06:40 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 16.116\u001b[0m\n",
      "\u001b[34m17:06:40 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 20.223\u001b[0m\n",
      "\u001b[34m17:06:40 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.5336538553237915\u001b[0m\n",
      "\u001b[32m17:06:40 [INFO] \u001b[37m(train-bert)\u001b[0m: Best validation loss so far\u001b[0m\n",
      "\u001b[34m17:06:41 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 6 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:12<00:00,  3.11it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  7.77it/s]\n",
      "\u001b[34m17:06:55 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 13.925\u001b[0m\n",
      "\u001b[34m17:06:55 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 22.105\u001b[0m\n",
      "\u001b[34m17:06:55 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.5480769276618958\u001b[0m\n",
      "\u001b[32m17:06:55 [INFO] \u001b[37m(train-bert)\u001b[0m: Not the best validation loss so far\u001b[0m\n",
      "\u001b[34m17:06:55 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 7 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.18it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  7.67it/s]\n",
      "\u001b[34m17:07:09 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 12.071\u001b[0m\n",
      "\u001b[34m17:07:09 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 21.373\u001b[0m\n",
      "\u001b[34m17:07:09 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.5769230723381042\u001b[0m\n",
      "\u001b[32m17:07:09 [INFO] \u001b[37m(train-bert)\u001b[0m: Not the best validation loss so far\u001b[0m\n",
      "\u001b[34m17:07:09 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 8 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:12<00:00,  3.15it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  7.64it/s]\n",
      "\u001b[34m17:07:22 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 9.793\u001b[0m\n",
      "\u001b[34m17:07:22 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 22.511\u001b[0m\n",
      "\u001b[34m17:07:22 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.567307710647583\u001b[0m\n",
      "\u001b[32m17:07:22 [INFO] \u001b[37m(train-bert)\u001b[0m: Not the best validation loss so far\u001b[0m\n",
      "\u001b[34m17:07:22 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 9 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:12<00:00,  3.16it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  7.43it/s]\n",
      "\u001b[34m17:07:36 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 8.834\u001b[0m\n",
      "\u001b[34m17:07:36 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 22.872\u001b[0m\n",
      "\u001b[34m17:07:36 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.5528846383094788\u001b[0m\n",
      "\u001b[32m17:07:36 [INFO] \u001b[37m(train-bert)\u001b[0m: Not the best validation loss so far\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 train_binary_bert.py --data_path \"swerick_subsetdata_party_train.csv\" --label_names $label_names_str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:31:33 [INFO] \u001b[37m(train-bert)\u001b[0m: Load and save tokenizer...\u001b[0m\n",
      "\u001b[32m14:31:33 [INFO] \u001b[37m(train-bert)\u001b[0m: Preprocess datasets...\u001b[0m\n",
      "\u001b[32m14:31:34 [INFO] \u001b[37m(train-bert)\u001b[0m: Labels: tensor([8, 8, 8, 8, 8, 3, 3, 3, 4, 3, 3, 8, 3, 3, 3, 3, 8, 3, 1, 8, 8, 8, 6, 8,\n",
      "        8, 8, 8, 8, 3, 3, 3, 8, 2, 3, 8, 3, 3, 3, 8, 8, 8, 8, 3, 3, 8, 8, 3, 2,\n",
      "        3, 8, 8, 8, 8, 8, 8, 3, 6, 8, 3, 3, 8, 3, 8, 3, 8, 8, 8, 3, 4, 8, 8, 8,\n",
      "        2, 3, 8, 3, 3, 8, 3, 3, 8, 2, 8, 8, 3, 3, 8, 3, 8, 8, 2, 3, 7, 3, 4, 8,\n",
      "        8, 8, 8, 3, 8, 8, 8, 3, 3, 8, 8, 8, 8, 8, 3, 3, 3, 8, 3, 4, 3, 3, 6, 8,\n",
      "        4, 8, 3, 3, 8, 8, 8, 3, 3, 8, 8, 3, 3, 8, 8, 3, 6, 8, 3, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 4, 8, 4, 8, 8, 3, 3, 8, 3, 8, 3, 8, 8, 3, 3, 8, 3, 7, 8, 8,\n",
      "        8, 3, 8, 3, 8, 4, 3, 2, 8, 8, 3, 3, 3, 8, 3, 2, 8, 8, 7, 8, 8, 2, 4, 8,\n",
      "        3, 8, 8, 8, 3, 8, 8, 8, 3, 3, 7, 8, 3, 3, 8, 8, 3, 8, 3, 8, 3, 3, 4, 8,\n",
      "        3, 8, 8, 8, 3, 8, 8, 3, 3, 3, 8, 8, 2, 8, 8, 2, 8, 8, 3, 8, 1, 6, 8, 8,\n",
      "        8, 3, 3, 3, 8, 6, 8, 3, 3, 6, 4, 2, 8, 3, 8, 4, 3, 8, 3, 3, 1, 8, 6, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 3, 8, 2, 8, 8, 8, 0, 8, 3, 3, 8, 3, 3, 8, 8, 3, 8,\n",
      "        8, 8, 8, 3, 3, 8, 8, 8, 3, 3, 8, 3, 3, 3, 3, 8, 8, 3, 6, 3, 8, 3, 8, 6,\n",
      "        8, 6, 3, 8, 8, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3, 8, 3, 8, 8, 8, 3, 7, 8, 3,\n",
      "        8, 3, 3, 3, 8, 3, 3, 3, 3, 8, 3, 4, 8, 8, 3, 3, 3, 8, 8, 8, 8, 8, 8, 3,\n",
      "        3, 8, 8, 8, 3, 3, 3, 3, 8, 8, 8, 8, 3, 3, 3, 3, 8, 8, 8, 8, 3, 3, 8, 3,\n",
      "        8, 8, 3, 4, 8, 3, 8, 3, 8, 3, 8, 8, 3, 3, 8, 3, 8, 8, 8, 8, 8, 3, 8, 8,\n",
      "        8, 8, 3, 3, 8, 3, 8, 8, 8, 8, 3, 3, 3, 8, 3, 8, 8, 6, 8, 8, 8, 3, 3, 8,\n",
      "        4, 8, 8, 3, 8, 2, 8, 1, 3, 8, 8, 3, 8, 3, 8, 3, 3, 8, 3, 0, 3, 8, 3, 8,\n",
      "        8, 8, 3, 3, 3, 7, 3, 3, 2, 8, 8, 8, 8, 3, 8, 3, 8, 3, 8, 3, 8, 4, 3, 8,\n",
      "        8, 3, 8, 8, 3, 8, 8, 8, 3, 3, 8, 8, 8, 3, 3, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        1, 8, 8, 2, 3, 8, 3, 3, 8, 3, 8, 3, 8, 8, 8, 3, 3, 8, 8, 3, 8, 3, 8, 8,\n",
      "        8, 3, 8, 3, 8, 8, 8, 3, 6, 3, 6, 3, 3, 3, 8, 3, 3, 3, 8, 8, 8, 8, 3, 3,\n",
      "        3, 6, 8, 8, 8, 8, 3, 3, 8, 3, 3, 8, 3, 8, 2, 8, 8, 8, 8, 3, 8, 8, 8, 8,\n",
      "        6, 8, 8, 3, 3, 8, 3, 8, 3, 2, 8, 8, 8, 8, 8, 4, 4, 3, 3, 8, 3, 3, 3, 8,\n",
      "        6, 8, 8, 8, 8, 8, 3, 3, 8, 3, 2, 3, 3, 1, 8, 6, 8, 8, 2, 8, 8, 3, 3, 3,\n",
      "        3, 3, 3, 8, 8, 4, 3, 8, 8, 3, 8, 3, 8, 8, 8, 2, 3, 3, 8, 3, 8, 3, 8, 8,\n",
      "        8, 8, 3, 3, 8, 8, 8, 8, 8, 3, 3, 8, 8, 3, 8, 3, 3, 8, 3, 2, 8, 8, 3, 3,\n",
      "        3, 8, 8, 3, 8, 8, 8, 8, 8, 3, 8, 3, 8, 4, 8, 8, 3, 8, 8, 3, 3, 3, 8, 3,\n",
      "        2, 3, 8, 8, 3, 8, 8, 3, 3, 3, 8, 3, 8, 3, 8, 8, 3, 3, 3, 8, 8, 6, 8, 3,\n",
      "        8, 3, 8, 8, 3, 3, 3, 3, 8, 3, 3, 4, 8, 3, 3, 8, 3, 8, 3, 3, 3, 0, 2, 8,\n",
      "        3, 2, 8, 3, 3, 8, 8, 8, 3, 3, 3, 2, 6, 3, 3, 8, 8, 3, 3, 8, 3, 6, 3, 8,\n",
      "        3, 6, 3, 8, 3, 8, 2, 8, 3, 8, 3, 3, 8, 2, 3, 8, 8, 6, 3, 8, 3, 3, 8, 8,\n",
      "        8, 2, 3, 3, 8, 8, 3, 8, 8, 3, 3, 8, 8, 3, 3, 8, 3, 8, 8, 8, 3, 3, 3, 3,\n",
      "        8, 3, 4, 8, 8, 8, 3, 8, 8, 3, 4, 3, 8, 8, 8, 8, 4, 3, 3, 3, 4, 3, 3, 8,\n",
      "        3, 8, 6, 3, 8, 3, 3, 3, 8, 3, 3, 3, 8, 3, 8, 8, 8, 8, 3, 3, 8, 8, 7, 7,\n",
      "        6, 3, 3, 8, 3, 3, 8, 3, 3, 3, 8, 3, 8, 3, 3, 8, 8, 8, 2, 8, 3, 8, 8, 8,\n",
      "        3, 3, 3, 8, 8, 8, 3, 3, 8, 8, 3, 3, 3, 8, 3, 3, 8, 8, 3, 8, 8, 3, 8, 8,\n",
      "        2, 8, 3, 3, 8, 3, 8, 3, 8, 3, 8, 8, 5, 3, 8, 8, 8, 3, 7, 3, 3, 8, 8, 8,\n",
      "        8, 3, 3, 8, 8, 3, 3, 3, 3, 8, 8, 2, 8, 3, 2, 8, 8, 8, 8, 8, 8, 3, 3, 6,\n",
      "        3, 8, 6, 3, 6, 8, 3, 8, 3, 3, 8, 3, 8, 8, 3, 3, 8, 8, 8, 2, 8, 3, 3, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 8, 2, 3, 8, 3, 3])\u001b[0m\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at finetuning_hugging_whitespace-finetuned-imdb/checkpoint-343500 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m14:31:35 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 0 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:12<00:00,  3.05it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.17it/s]\n",
      "\u001b[34m14:31:49 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 25.688\u001b[0m\n",
      "\u001b[34m14:31:49 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 18.777\u001b[0m\n",
      "\u001b[34m14:31:49 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.4759615361690521\u001b[0m\n",
      "\u001b[32m14:31:49 [INFO] \u001b[37m(train-bert)\u001b[0m: Best validation loss so far\u001b[0m\n",
      "\u001b[34m14:31:50 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 1 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.35it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.48it/s]\n",
      "\u001b[34m14:32:03 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 18.494\u001b[0m\n",
      "\u001b[34m14:32:03 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 18.382\u001b[0m\n",
      "\u001b[34m14:32:03 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.4759615361690521\u001b[0m\n",
      "\u001b[32m14:32:03 [INFO] \u001b[37m(train-bert)\u001b[0m: Best validation loss so far\u001b[0m\n",
      "\u001b[34m14:32:04 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 2 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.32it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.27it/s]\n",
      "\u001b[34m14:32:17 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 18.258\u001b[0m\n",
      "\u001b[34m14:32:17 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 17.982\u001b[0m\n",
      "\u001b[34m14:32:17 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.4711538553237915\u001b[0m\n",
      "\u001b[32m14:32:17 [INFO] \u001b[37m(train-bert)\u001b[0m: Best validation loss so far\u001b[0m\n",
      "\u001b[34m14:32:18 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 3 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.27it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.29it/s]\n",
      "\u001b[34m14:32:31 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 17.579\u001b[0m\n",
      "\u001b[34m14:32:31 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 17.463\u001b[0m\n",
      "\u001b[34m14:32:31 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.504807710647583\u001b[0m\n",
      "\u001b[32m14:32:31 [INFO] \u001b[37m(train-bert)\u001b[0m: Best validation loss so far\u001b[0m\n",
      "\u001b[34m14:32:32 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 4 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:12<00:00,  3.10it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  7.89it/s]\n",
      "\u001b[34m14:32:46 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 16.482\u001b[0m\n",
      "\u001b[34m14:32:46 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 17.295\u001b[0m\n",
      "\u001b[34m14:32:46 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.5384615659713745\u001b[0m\n",
      "\u001b[32m14:32:46 [INFO] \u001b[37m(train-bert)\u001b[0m: Best validation loss so far\u001b[0m\n",
      "\u001b[34m14:32:48 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 5 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.32it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.49it/s]\n",
      "\u001b[34m14:33:01 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 14.681\u001b[0m\n",
      "\u001b[34m14:33:01 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 17.537\u001b[0m\n",
      "\u001b[34m14:33:01 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.5480769276618958\u001b[0m\n",
      "\u001b[32m14:33:01 [INFO] \u001b[37m(train-bert)\u001b[0m: Not the best validation loss so far\u001b[0m\n",
      "\u001b[34m14:33:01 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 6 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.28it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.29it/s]\n",
      "\u001b[34m14:33:14 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 12.804\u001b[0m\n",
      "\u001b[34m14:33:14 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 19.999\u001b[0m\n",
      "\u001b[34m14:33:14 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.49038460850715637\u001b[0m\n",
      "\u001b[32m14:33:14 [INFO] \u001b[37m(train-bert)\u001b[0m: Not the best validation loss so far\u001b[0m\n",
      "\u001b[34m14:33:14 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 7 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.33it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.40it/s]\n",
      "\u001b[34m14:33:27 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 11.140\u001b[0m\n",
      "\u001b[34m14:33:27 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 17.909\u001b[0m\n",
      "\u001b[34m14:33:27 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.557692289352417\u001b[0m\n",
      "\u001b[32m14:33:27 [INFO] \u001b[37m(train-bert)\u001b[0m: Not the best validation loss so far\u001b[0m\n",
      "\u001b[34m14:33:27 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 8 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.35it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.51it/s]\n",
      "\u001b[34m14:33:39 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 8.879\u001b[0m\n",
      "\u001b[34m14:33:39 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 18.765\u001b[0m\n",
      "\u001b[34m14:33:39 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.5865384340286255\u001b[0m\n",
      "\u001b[32m14:33:39 [INFO] \u001b[37m(train-bert)\u001b[0m: Not the best validation loss so far\u001b[0m\n",
      "\u001b[34m14:33:39 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Epoch 9 starts!\u001b[0m\n",
      "100%|███████████████████████████████████████████| 38/38 [00:11<00:00,  3.35it/s]\n",
      "100%|███████████████████████████████████████████| 13/13 [00:01<00:00,  8.32it/s]\n",
      "\u001b[34m14:33:52 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Training Loss: 7.990\u001b[0m\n",
      "\u001b[34m14:33:52 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation Loss: 18.964\u001b[0m\n",
      "\u001b[34m14:33:52 [TRAIN] \u001b[37m(train-bert)\u001b[0m: Validation accuracy: 0.5961538553237915\u001b[0m\n",
      "\u001b[32m14:33:52 [INFO] \u001b[37m(train-bert)\u001b[0m: Not the best validation loss so far\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 train_binary_bert.py --model_filename \"trained_hugging_face_party_classification\" --base_model \"finetuning_hugging_whitespace-finetuned-imdb/checkpoint-343500\" --data_path \"swerick_subsetdata_party_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'vänstern' 'Andra kammarens center' 'Andra kammarens frihandelsparti' 'Bondeförbundet' 'Centern (partigrupp 1873-1882)' 'Centern (partigrupp 1885-1887)' 'Centerpartiet' 'Det förenade högerpartiet' 'Ehrenheimska partiet' 'Folkpartiet' 'Folkpartiet (1895–1900)' 'Friesenska diskussionsklubben' 'Frihandelsvänliga centern' 'Frisinnade folkpartiet' 'Frisinnade försvarsvänner' 'Frisinnade landsföreningen' 'Första kammarens konservativa grupp' 'Första kammarens ministeriella grupp' 'Första kammarens minoritetsparti' 'Första kammarens moderata parti' 'Första kammarens nationella parti' 'Första kammarens protektionistiska parti' 'Gamla lantmannapartiet' 'Högerns riksdagsgrupp' 'Högerpartiet' 'Högerpartiet de konservativa' 'Jordbrukarnas fria grupp' 'Junkerpartiet' 'Kilbomspartiet' 'Kommunistiska partiet' 'Kristdemokraterna' 'Lantmanna- och borgarepartiet inom andrakammaren' 'Lantmannapartiet' 'Lantmannapartiets filial' 'Liberala riksdagspartiet' 'Liberala samlingspartiet' 'Liberalerna' 'Medborgerlig samling (1964–1968)' 'Miljöpartiet' 'Moderaterna' 'Nationella framstegspartiet' 'Ny demokrati' 'Nya centern (partigrupp 1883-1887)' 'Nya lantmannapartiet' 'Nyliberala partiet' 'Skånska partiet' 'Socialdemokraterna' 'Socialdemokratiska vänstergruppen' 'Socialistiska partiet' 'Stockholmsbänken' 'Sverigedemokraterna' 'Sveriges kommunistiska parti' 'Vänsterpartiet' 'borgmästarepartiet' 'frihandelsvänlig vilde' 'frisinnad vilde' 'högervilde' 'ministeriella partiet' 'partilös' 'politisk vilde' 'vänstervilde'\"]\n",
      "{0: \"'vänstern' 'Andra kammarens center' 'Andra kammarens frihandelsparti' 'Bondeförbundet' 'Centern (partigrupp 1873-1882)' 'Centern (partigrupp 1885-1887)' 'Centerpartiet' 'Det förenade högerpartiet' 'Ehrenheimska partiet' 'Folkpartiet' 'Folkpartiet (1895–1900)' 'Friesenska diskussionsklubben' 'Frihandelsvänliga centern' 'Frisinnade folkpartiet' 'Frisinnade försvarsvänner' 'Frisinnade landsföreningen' 'Första kammarens konservativa grupp' 'Första kammarens ministeriella grupp' 'Första kammarens minoritetsparti' 'Första kammarens moderata parti' 'Första kammarens nationella parti' 'Första kammarens protektionistiska parti' 'Gamla lantmannapartiet' 'Högerns riksdagsgrupp' 'Högerpartiet' 'Högerpartiet de konservativa' 'Jordbrukarnas fria grupp' 'Junkerpartiet' 'Kilbomspartiet' 'Kommunistiska partiet' 'Kristdemokraterna' 'Lantmanna- och borgarepartiet inom andrakammaren' 'Lantmannapartiet' 'Lantmannapartiets filial' 'Liberala riksdagspartiet' 'Liberala samlingspartiet' 'Liberalerna' 'Medborgerlig samling (1964–1968)' 'Miljöpartiet' 'Moderaterna' 'Nationella framstegspartiet' 'Ny demokrati' 'Nya centern (partigrupp 1883-1887)' 'Nya lantmannapartiet' 'Nyliberala partiet' 'Skånska partiet' 'Socialdemokraterna' 'Socialdemokratiska vänstergruppen' 'Socialistiska partiet' 'Stockholmsbänken' 'Sverigedemokraterna' 'Sveriges kommunistiska parti' 'Vänsterpartiet' 'borgmästarepartiet' 'frihandelsvänlig vilde' 'frisinnad vilde' 'högervilde' 'ministeriella partiet' 'partilös' 'politisk vilde' 'vänstervilde'\"}\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/laurinemeier/swerick/train_binary_bert.py\", line 209, in <module>\n",
      "    main(args)\n",
      "  File \"/home/laurinemeier/swerick/train_binary_bert.py\", line 85, in main\n",
      "    df[\"tag\"] = [bidict(label_dict).inv[tag] for tag in df[\"tag\"]]\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/laurinemeier/swerick/train_binary_bert.py\", line 85, in <listcomp>\n",
      "    df[\"tag\"] = [bidict(label_dict).inv[tag] for tag in df[\"tag\"]]\n",
      "                 ~~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "  File \"/home/laurinemeier/anaconda3/lib/python3.11/site-packages/bidict/_base.py\", line 524, in __getitem__\n",
      "    return self._fwdm[key]\n",
      "           ~~~~~~~~~~^^^^^\n",
      "KeyError: 'ministeriella partiet'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Votre liste de noms de labels\n",
    "import subprocess\n",
    "\n",
    "label_names = [\n",
    "    'vänstern', 'Andra kammarens center', 'Andra kammarens frihandelsparti', 'Bondeförbundet',\n",
    "    'Centern (partigrupp 1873-1882)', 'Centern (partigrupp 1885-1887)', 'Centerpartiet',\n",
    "    'Det förenade högerpartiet', 'Ehrenheimska partiet', 'Folkpartiet', 'Folkpartiet (1895–1900)',\n",
    "    'Friesenska diskussionsklubben', 'Frihandelsvänliga centern', 'Frisinnade folkpartiet',\n",
    "    'Frisinnade försvarsvänner', 'Frisinnade landsföreningen', 'Första kammarens konservativa grupp',\n",
    "    'Första kammarens ministeriella grupp', 'Första kammarens minoritetsparti',\n",
    "    'Första kammarens moderata parti', 'Första kammarens nationella parti',\n",
    "    'Första kammarens protektionistiska parti', 'Gamla lantmannapartiet', 'Högerns riksdagsgrupp',\n",
    "    'Högerpartiet', 'Högerpartiet de konservativa', 'Jordbrukarnas fria grupp', 'Junkerpartiet',\n",
    "    'Kilbomspartiet', 'Kommunistiska partiet', 'Kristdemokraterna',\n",
    "    'Lantmanna- och borgarepartiet inom andrakammaren', 'Lantmannapartiet', 'Lantmannapartiets filial',\n",
    "    'Liberala riksdagspartiet', 'Liberala samlingspartiet', 'Liberalerna',\n",
    "    'Medborgerlig samling (1964–1968)', 'Miljöpartiet', 'Moderaterna', 'Nationella framstegspartiet',\n",
    "    'Ny demokrati', 'Nya centern (partigrupp 1883-1887)', 'Nya lantmannapartiet', 'Nyliberala partiet',\n",
    "    'Skånska partiet', 'Socialdemokraterna', 'Socialdemokratiska vänstergruppen', 'Socialistiska partiet',\n",
    "    'Stockholmsbänken', 'Sverigedemokraterna', 'Sveriges kommunistiska parti', 'Vänsterpartiet',\n",
    "    'borgmästarepartiet', 'frihandelsvänlig vilde', 'frisinnad vilde', 'högervilde', 'ministeriella partiet',\n",
    "    'partilös', 'politisk vilde', 'vänstervilde'\n",
    "]\n",
    "\n",
    "# Ajouter les guillemets simples autour de chaque nom de label\n",
    "label_names_str = ' '.join([f\"'{label}'\" for label in label_names])\n",
    "\n",
    "# Votre commande\n",
    "command = [\n",
    "    \"python3\",\n",
    "    \"train_binary_bert.py\",\n",
    "    \"--model_filename\",\n",
    "    \"trained_hugging_face_party_classification\",\n",
    "    \"--base_model\",\n",
    "    \"finetuning_hugging_whitespace-finetuned-imdb/checkpoint-343500\",\n",
    "    \"--data_path\",\n",
    "    \"swerick_subsetdata_party_train.csv\",\n",
    "    \"--label_names\",\n",
    "    label_names_str\n",
    "]\n",
    "\n",
    "# Exécuter la commande\n",
    "process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = process.communicate()\n",
    "\n",
    "# Imprimer la sortie\n",
    "print(stdout.decode())\n",
    "print(stderr.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swerick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
