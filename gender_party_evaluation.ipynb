{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laurinemeier/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing\n",
    "import argparse\n",
    "import preprocessing\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at KBLab/bert-base-swedish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"KBLab/bert-base-swedish-cased\"\n",
    "model =  AutoModelForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at finetuning_hugging_python-finetuned-imdb/checkpoint-920384 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_finetuned = AutoModelForSequenceClassification.from_pretrained(\"finetuning_hugging_python-finetuned-imdb/checkpoint-920384\")\n",
    "model_finetuned=model_finetuned.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3378877 examples [00:18, 179532.30 examples/s]\n",
      "Generating test split: 725974 examples [00:03, 205408.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['protocole', 'Note', 'id', 'party', 'gender'],\n",
      "        num_rows: 3378877\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['protocole', 'Note', 'id', 'party', 'gender'],\n",
      "        num_rows: 725974\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_files = {\"train\": \"swerick_data_party_train.pkl\", \"test\": \"swerick_data_party_test.pkl\"}\n",
    "party_dataset = load_dataset(\"pandas\",data_files=data_files)\n",
    "print(party_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'protocole': 'data/1867/prot-1867--ak--0119.xml',\n",
       " 'Note': 'För min del kan jag ej se något hinder för företagande af dessa\\n            val ännu något tidigare än Herr Talmannen föreslagit. Jag har\\n            föreställt mig, att vi så mycket som möjligt borde taga vara på\\n            den dyrbara tiden, och att nu ifrågakomna val kunde förrättas\\n            t. ex. på Tisdagen, och valen till suppleanter i Utskotten på\\n            Thorsdagen.',\n",
       " 'id': 'i-PyY1Vo1W6WaajphhpnKHN8',\n",
       " 'party': None,\n",
       " 'gender': 'man'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_dataset[\"train\"][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification for parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 3378877/3378877 [00:18<00:00, 179660.27 examples/s]\n",
      "Filter: 100%|██████████| 725974/725974 [00:04<00:00, 178776.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def filter_Nan(subset,example):\n",
    "    return example[subset] is not None\n",
    "\n",
    "\n",
    "party_dataset['train']=party_dataset['train'].filter(lambda x: filter_Nan('party',x))\n",
    "party_dataset['test']=party_dataset['test'].filter(lambda x: filter_Nan('party',x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3167750/3167750 [08:30<00:00, 6211.09 examples/s]\n",
      "Map: 100%|██████████| 676215/676215 [01:50<00:00, 6125.07 examples/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m party_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m party_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m example: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparty_label\u001b[39m\u001b[38;5;124m'\u001b[39m: label_encoder\u001b[38;5;241m.\u001b[39mtransform([example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparty\u001b[39m\u001b[38;5;124m'\u001b[39m]])[\u001b[38;5;241m0\u001b[39m]}, \n\u001b[1;32m      4\u001b[0m                                                     remove_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparty\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m party_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m party_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m example: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparty_label\u001b[39m\u001b[38;5;124m'\u001b[39m: label_encoder\u001b[38;5;241m.\u001b[39mtransform([example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparty\u001b[39m\u001b[38;5;124m'\u001b[39m]])[\u001b[38;5;241m0\u001b[39m]}, \n\u001b[1;32m      6\u001b[0m                                                     remove_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparty\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mparty_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(party_dataset['train']['party'])\n",
    "party_dataset['train'] = party_dataset['train'].map(lambda example: {'party_label': label_encoder.transform([example['party']])[0]}, \n",
    "                                                    remove_columns=['party'])\n",
    "party_dataset['test'] = party_dataset['test'].map(lambda example: {'party_label': label_encoder.transform([example['party']])[0]}, \n",
    "                                                    remove_columns=['party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'party_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mparty_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mfeatures\n",
      "\u001b[0;31mNameError\u001b[0m: name 'party_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "party_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_dataset=party_dataset.remove_columns(\"gender\",\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example,subset):\n",
    "    return tokenizer(example[subset], truncation=True,\n",
    "                    add_special_tokens = True,\n",
    "                    max_length = 512,\n",
    "                    padding = 'max_length',\n",
    "                    return_attention_mask = True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_tokenized = party_dataset.map(lambda x:tokenize_function(x,\"Note\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "batch_size=64\n",
    "num_workers=4\n",
    "train_loader = DataLoader(\n",
    "            party_dataset[\"train],\n",
    "            shuffle=True,\n",
    "            batch_size = batch_size,\n",
    "            num_workers = num_workers\n",
    "        )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "            party_dataset[\"test],\n",
    "            shuffle=False,\n",
    "            batch_size = batch_size,\n",
    "            num_workers = num_workers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"finetuning_hugging_python-finetuned-imdb/checkpoint-920384\",\n",
    "        num_labels=len(label_encoder),\n",
    "        id2label=label_dict).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), lr=args.learning_rate)\n",
    "num_training_steps = len(train_loader) * args.n_epochs\n",
    "num_warmup_steps = num_training_steps // 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Linear warmup and step decay\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer = optimizer,\n",
    "        num_warmup_steps = num_warmup_steps,\n",
    "        num_training_steps = num_training_steps\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    loss, accuracy = 0.0, []\n",
    "    model.eval()\n",
    "    for batch in tqdm(loader, total=len(loader)):\n",
    "        input_ids = batch[0].to(args.device)\n",
    "        input_mask = batch[1].to(args.device)\n",
    "        labels = batch[2].to(args.device)\n",
    "        output = model(input_ids,\n",
    "            token_type_ids=None, \n",
    "            attention_mask=input_mask, \n",
    "            labels=labels)\n",
    "        loss += output.loss.item()\n",
    "        preds_batch = torch.argmax(output.logits, axis=1)\n",
    "        batch_acc = torch.mean((preds_batch == labels).float())\n",
    "        accuracy.append(batch_acc)\n",
    "        \n",
    "    accuracy = torch.mean(torch.tensor(accuracy))\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch=10\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch} starts!\")\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader, total=len(train_loader)):\n",
    "        model.zero_grad()   \n",
    "\n",
    "        input_ids = batch[0].to(device)\n",
    "        input_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        output = model(input_ids,\n",
    "            token_type_ids=None, \n",
    "            attention_mask=input_mask, \n",
    "            labels=labels)\n",
    "        loss = output.loss\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    train_loss_avg = train_loss * args.batch_size / len(train_loader)\n",
    "    valid_loss_avg = valid_loss * args.batch_size / len(valid_loader)\n",
    "\n",
    "    print(f'Training Loss: {train_loss_avg:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss_avg:.3f}')\n",
    "    print(f'Validation accuracy: {valid_accuracy}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model():\n",
    "    loss1, accuracy1 = 0.0, []\n",
    "    loss2, accuracy2 = 0.0, []\n",
    "    model.eval()\n",
    "    model_hugging_face.eval()\n",
    "    true_labels, pred_labels1, pred_labels2 = [], [], []\n",
    "    for batch in tqdm(loader, total=len(loader)):\n",
    "        input_ids = batch[0].to(args.device)\n",
    "        input_mask = batch[1].to(args.device)\n",
    "        labels = batch[2].to(args.device)\n",
    "        output1 = model1(input_ids, token_type_ids=None, attention_mask=input_mask, labels=labels)\n",
    "        output2 = model2(input_ids, token_type_ids=None, attention_mask=input_mask, labels=labels)\n",
    "        loss1 += output1.loss.item()\n",
    "        loss2 += output2.loss.item()\n",
    "        preds_batch1 = torch.argmax(output1.logits, axis=1)\n",
    "        preds_batch2 = torch.argmax(output2.logits, axis=1)\n",
    "        batch_acc1 = torch.mean((preds_batch1 == labels).float())\n",
    "        batch_acc2 = torch.mean((preds_batch2 == labels).float())\n",
    "        accuracy1.append(batch_acc1)\n",
    "        accuracy2.append(batch_acc2)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels1.extend(preds_batch1.cpu().numpy())\n",
    "        pred_labels2.extend(preds_batch2.cpu().numpy())\n",
    "            \n",
    "            for true_label, pred_label1, pred_label2 , input_id  in zip(labels, preds_batch1, preds_batch2, input_ids):\n",
    "                if true_label != pred_label1 or true_label != pred_label2 :\n",
    "                    text = tokenizer.decode(input_id, skip_special_tokens=True)\n",
    "                    matching_rows = dataset[dataset['content'].apply(lambda x: Levenshtein.ratio(text, x) >= 0.9)]\n",
    "                    if not matching_rows.empty:\n",
    "                        github = matching_rows['github'].iloc[0]\n",
    "                        protocol_id = matching_rows['protocol_id'].iloc[0]\n",
    "\n",
    "                        misclassified_examples.append({'text': text, 'true_label': label_names[true_label.item()], 'predicted1':label_names[pred_label1.item()],'predicted2':label_names[pred_label2.item()], 'github': github, 'protocol_id': protocol_id})\n",
    "                    else:\n",
    "                        print(f\"no matching row for text: {text}\")\n",
    "\n",
    "        misclassified_df = pd.DataFrame(misclassified_examples)\n",
    "        misclassified_df.to_csv('data/compare_misclassified_examples.csv', index=False, columns=['text', 'true_label', 'predicted1', 'predicted2', 'github', 'protocol_id'])\n",
    "        \n",
    "    # Print misclassified examples\n",
    "        print(\"\\nMisclassified Examples:\")\n",
    "        print(misclassified_examples)\n",
    "\n",
    "        print(\"\\nAccuracy model 1:\", accuracy_score(true_labels, pred_labels1))\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(true_labels, pred_labels1, target_names=list(label_names)))\n",
    "\n",
    "        \n",
    "        print(\"\\nAccuracy model 2:\", accuracy_score(true_labels, pred_labels2))\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(true_labels, pred_labels2, target_names=list(label_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swerick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
