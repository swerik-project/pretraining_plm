{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoModelForSequenceClassification,AutoTokenizer\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing\n",
    "import argparse\n",
    "import preprocessing\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at KBLab/bert-base-swedish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"KBLab/bert-base-swedish-cased\"\n",
    "model =  AutoModelForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at finetuning_hugging_python-finetuned-imdb/checkpoint-920384 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_finetuned = AutoModelForSequenceClassification.from_pretrained(\"finetuning_hugging_python-finetuned-imdb/checkpoint-920384\")\n",
    "model_finetuned=model_finetuned.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer= AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_NaN(subset,example):\n",
    "    return example[subset] is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset(dataset,nb_obs):\n",
    "    total_sample=len(dataset)\n",
    "    subset_size=nb_obs\n",
    "    num_subset = total_sample//subset_size +(0 if total_sample%subset_size==0 else 1)\n",
    "    sub_datasets=[]\n",
    "    for i in range(num_subset):\n",
    "        start_index=i*subset_size\n",
    "        end_index = min((i+1)*subset_size,total_sample)\n",
    "        sub_dataset=dataset.select(indices=range(start_index,end_index))\n",
    "        sub_datasets.append(sub_dataset)\n",
    "    return sub_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"Note\"],padding=True, truncation=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['protocole', 'Note', 'id', 'party', 'gender'],\n",
      "        num_rows: 3378877\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['protocole', 'Note', 'id', 'party', 'gender'],\n",
      "        num_rows: 725974\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_files = {\"train\": \"swerick_data_party_train.pkl\", \"test\": \"swerick_data_party_test.pkl\"}\n",
    "party_dataset = load_dataset(\"pandas\",data_files=data_files)\n",
    "print(party_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ec0e0e8920477fa20c53e619a487e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    valid: Dataset({\n",
      "        features: ['protocole', 'Note', 'id', 'party', 'gender'],\n",
      "        num_rows: 725974\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_files = {\"valid\": \"swerick_data_party_valid.pkl\"}\n",
    "party_valid_dataset = load_dataset(\"pandas\",data_files=data_files)\n",
    "print(party_valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f88b37732744daa00fd112caa3347f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3378877 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d7cf3a0e9949c394f37e03f7870f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/725974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "party_dataset[\"train\"]=party_dataset[\"train\"].filter(lambda x : filter_NaN(\"party\",x))\n",
    "party_dataset[\"test\"]=party_dataset[\"test\"].filter(lambda x : filter_NaN(\"party\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4148c97880284d23b703d3e5ed5f0ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/725974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "party_valid_dataset[\"valid\"]=party_valid_dataset[\"valid\"].filter(lambda x : filter_NaN(\"party\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\"vänstern\"', 1: 'Andra kammarens center', 2: 'Andra kammarens frihandelsparti', 3: 'Bondeförbundet', 4: 'Centern (partigrupp 1873-1882)', 5: 'Centern (partigrupp 1885-1887)', 6: 'Centerpartiet', 7: 'Det förenade högerpartiet', 8: 'Ehrenheimska partiet', 9: 'Folkpartiet', 10: 'Folkpartiet (1895–1900)', 11: 'Friesenska diskussionsklubben', 12: 'Frihandelsvänliga centern', 13: 'Frisinnade folkpartiet', 14: 'Frisinnade försvarsvänner', 15: 'Frisinnade landsföreningen', 16: 'Första kammarens konservativa grupp', 17: 'Första kammarens ministeriella grupp', 18: 'Första kammarens minoritetsparti', 19: 'Första kammarens moderata parti', 20: 'Första kammarens nationella parti', 21: 'Första kammarens protektionistiska parti', 22: 'Gamla lantmannapartiet', 23: 'Högerns riksdagsgrupp', 24: 'Högerpartiet', 25: 'Högerpartiet de konservativa', 26: 'Jordbrukarnas fria grupp', 27: 'Junkerpartiet', 28: 'Kilbomspartiet', 29: 'Kommunistiska partiet', 30: 'Kristdemokraterna', 31: 'Lantmanna- och borgarepartiet inom andrakammaren', 32: 'Lantmannapartiet', 33: 'Lantmannapartiets filial', 34: 'Liberala riksdagspartiet', 35: 'Liberala samlingspartiet', 36: 'Liberalerna', 37: 'Medborgerlig samling (1964–1968)', 38: 'Miljöpartiet', 39: 'Moderaterna', 40: 'Nationella framstegspartiet', 41: 'Ny demokrati', 42: 'Nya centern (partigrupp 1883-1887)', 43: 'Nya lantmannapartiet', 44: 'Nyliberala partiet', 45: 'Skånska partiet', 46: 'Socialdemokraterna', 47: 'Socialdemokratiska vänstergruppen', 48: 'Socialistiska partiet', 49: 'Stockholmsbänken', 50: 'Sverigedemokraterna', 51: 'Sveriges kommunistiska parti', 52: 'Vänsterpartiet', 53: 'borgmästarepartiet', 54: 'frihandelsvänlig vilde', 55: 'frisinnad vilde', 56: 'högervilde', 57: 'ministeriella partiet', 58: 'partilös', 59: 'politisk vilde', 60: 'vänstervilde'}\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(party_dataset[\"train\"][\"party\"])\n",
    "label_names = label_encoder.classes_\n",
    "label_dict={ i : label_names[i] for i in  range(len(label_names))}\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd66216ff8b7498b82f317f5fa70a787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3167750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb7d5b1dc7343d29302a461e6bb589a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/676215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "party_dataset[\"train\"]=party_dataset[\"train\"].map(lambda example :{\"party_labels\" : label_encoder.transform([example[\"party\"]])[0]})\n",
    "party_dataset[\"test\"]=party_dataset[\"test\"].map(lambda example :{\"party_labels\" : label_encoder.transform([example[\"party\"]])[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b08effd0de948f9adad4a48eea250c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/676215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "party_valid_dataset[\"valid\"]=party_valid_dataset[\"valid\"].map(lambda example :{\"party_labels\" : label_encoder.transform([example[\"party\"]])[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_binary_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_train_datasets = subset(party_dataset[\"train\"],1000)\n",
    "party_test_datasets = subset(party_dataset[\"test\"],10000)\n",
    "party_valid_datasets = subset(party_valid_dataset[\"valid\"],10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = party_train_datasets[0]\n",
    "test_set = party_test_datasets[0]\n",
    "valid_set = party_valid_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bb2f5b7ad44f5894e774959cc71ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6fa1507535403ca01b76e09d0c2998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40d5f95f9304247a6a02bfd52b015db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['protocole', 'Note', 'id', 'party', 'gender', 'party_labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_datasets = train_set.map(tokenize_function,batched=True )\n",
    "tokenized_test_datasets = test_set.map(tokenize_function,batched=True )\n",
    "tokenized_valid_datasets = valid_set.map(tokenize_function,batched=True )\n",
    "tokenized_train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " train_loader = DataLoader(\n",
    "            tokenized_train_datasets,\n",
    "            shuffle=True,\n",
    "            batch_size = batch_size,\n",
    "            num_workers = num_workers\n",
    "        )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "            tokenized_valid_datasets,\n",
    "            shuffle=False,\n",
    "            batch_size = batch_size,\n",
    "            num_workers = num_workers\n",
    "        )\n",
    "\n",
    "    # Not used atm\n",
    "    test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            shuffle=False,\n",
    "            batch_size = args.batch_size,\n",
    "            num_workers = args.num_workers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train_binary_bert.py [-h] [--model_filename MODEL_FILENAME]\n",
      "                            [--base_model BASE_MODEL] [--tokenizer TOKENIZER]\n",
      "                            [--label_names LABEL_NAMES [LABEL_NAMES ...]]\n",
      "                            [--train_set TRAIN_SET] [--test_set TEST_SET]\n",
      "                            [--valid_set VALID_SET] [--device DEVICE]\n",
      "                            [--n_epochs N_EPOCHS] [--batch_size BATCH_SIZE]\n",
      "                            [--num_workers NUM_WORKERS]\n",
      "                            [--learning_rate LEARNING_RATE]\n",
      "                            [--train_ratio TRAIN_RATIO]\n",
      "                            [--valid_ratio VALID_RATIO]\n",
      "train_binary_bert.py: error: argument --train_set: invalid Dataset value: 'swerick_data_party_train.pkl'\n",
      "fish: Unknown command: Bondeförbundet\n",
      "fish: \n",
      " 'Bondeförbundet' 'Centern (partigrupp 1873-1882)'\n",
      " ^\n",
      "fish: Unknown command: 'Centern (partigrupp 1885-1887)'\n",
      "fish: \n",
      " 'Centern (partigrupp 1885-1887)' 'Centerpartiet'\n",
      " ^\n",
      "fish: Unknown command: 'Det förenade högerpartiet'\n",
      "fish: \n",
      " 'Det förenade högerpartiet' 'Ehrenheimska partiet' 'Folkpartiet'\n",
      " ^\n",
      "fish: Unknown command: 'Folkpartiet (1895–1900)'\n",
      "fish: \n",
      " 'Folkpartiet (1895–1900)' 'Friesenska diskussionsklubben'\n",
      " ^\n",
      "fish: Unknown command: 'Frihandelsvänliga centern'\n",
      "fish: \n",
      " 'Frihandelsvänliga centern' 'Frisinnade folkpartiet'\n",
      " ^\n",
      "fish: Unknown command: 'Frisinnade försvarsvänner'\n",
      "fish: \n",
      " 'Frisinnade försvarsvänner' 'Frisinnade landsföreningen'\n",
      " ^\n",
      "fish: Unknown command: 'Första kammarens konservativa grupp'\n",
      "fish: \n",
      " 'Första kammarens konservativa grupp'\n",
      " ^\n",
      "fish: Unknown command: 'Första kammarens ministeriella grupp'\n",
      "fish: \n",
      " 'Första kammarens ministeriella grupp' 'Första kammarens minoritetsparti'\n",
      " ^\n",
      "fish: Unknown command: 'Första kammarens moderata parti'\n",
      "fish: \n",
      " 'Första kammarens moderata parti' 'Första kammarens nationella parti'\n",
      " ^\n",
      "fish: Unknown command: 'Första kammarens protektionistiska parti'\n",
      "fish: \n",
      " 'Första kammarens protektionistiska parti' 'Gamla lantmannapartiet'\n",
      " ^\n",
      "fish: Unknown command: 'Högerns riksdagsgrupp'\n",
      "fish: \n",
      " 'Högerns riksdagsgrupp' 'Högerpartiet' 'Högerpartiet de konservativa'\n",
      " ^\n",
      "fish: Unknown command: 'Jordbrukarnas fria grupp'\n",
      "fish: \n",
      " 'Jordbrukarnas fria grupp' 'Junkerpartiet' 'Kilbomspartiet'\n",
      " ^\n",
      "fish: Unknown command: 'Kommunistiska partiet'\n",
      "fish: \n",
      " 'Kommunistiska partiet' 'Kristdemokraterna'\n",
      " ^\n",
      "fish: Unknown command: 'Lantmanna- och borgarepartiet inom andrakammaren'\n",
      "fish: \n",
      " 'Lantmanna- och borgarepartiet inom andrakammaren' 'Lantmannapartiet'\n",
      " ^\n",
      "fish: Unknown command: 'Lantmannapartiets filial'\n",
      "fish: \n",
      " 'Lantmannapartiets filial' 'Liberala riksdagspartiet'\n",
      " ^\n",
      "fish: Unknown command: 'Liberala samlingspartiet'\n",
      "fish: \n",
      " 'Liberala samlingspartiet' 'Liberalerna'\n",
      " ^\n",
      "fish: Unknown command: 'Medborgerlig samling (1964–1968)'\n",
      "fish: \n",
      " 'Medborgerlig samling (1964–1968)' 'Miljöpartiet' 'Moderaterna'\n",
      " ^\n",
      "fish: Unknown command: 'Nationella framstegspartiet'\n",
      "fish: \n",
      " 'Nationella framstegspartiet' 'Ny demokrati'\n",
      " ^\n",
      "fish: Unknown command: 'Nya centern (partigrupp 1883-1887)'\n",
      "fish: \n",
      " 'Nya centern (partigrupp 1883-1887)' 'Nya lantmannapartiet'\n",
      " ^\n",
      "fish: Unknown command: 'Nyliberala partiet'\n",
      "fish: \n",
      " 'Nyliberala partiet' 'Skånska partiet' 'Socialdemokraterna'\n",
      " ^\n",
      "fish: Unknown command: 'Socialdemokratiska vänstergruppen'\n",
      "fish: \n",
      " 'Socialdemokratiska vänstergruppen' 'Socialistiska partiet'\n",
      " ^\n",
      "fish: Unknown command: Stockholmsbänken\n",
      "fish: \n",
      " 'Stockholmsbänken' 'Sverigedemokraterna' 'Sveriges kommunistiska parti'\n",
      " ^\n",
      "fish: Unknown command: Vänsterpartiet\n",
      "fish: \n",
      " 'Vänsterpartiet' 'borgmästarepartiet' 'frihandelsvänlig vilde'\n",
      " ^\n",
      "fish: Unknown command: 'frisinnad vilde'\n",
      "fish: \n",
      " 'frisinnad vilde' 'högervilde' 'ministeriella partiet' 'partilös'\n",
      " ^\n",
      "fish: Unknown command: \\n\\ \\ \\ \\ features:\\ \\[protocole\n",
      "fish: \n",
      "{\n",
      "    features: ['protocole', 'Note', 'id', 'party', 'gender', 'party_labels'],\n",
      "    num_rows: 1000\n",
      "}\n",
      "^\n",
      "in command substitution\n",
      "fish: Unknown command\n",
      " 'politisk vilde' 'vänstervilde'] --train_set Dataset({\n",
      "                                                     ^\n"
     ]
    }
   ],
   "source": [
    "!python3 train_binary_bert.py --label_names {label_names} --train_set {train_set} --test_set test_set --valid_set valid_set --batch_size 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1, accuracy1 = 0.0, []\n",
    "loss2, accuracy2 = 0.0, []\n",
    "model.eval()\n",
    "model_hugging_face.eval()\n",
    "true_labels, pred_labels1, pred_labels2 = [], [], []\n",
    "for batch in tqdm(loader, total=len(loader)):\n",
    "    input_ids = batch[0].to(args.device)\n",
    "    input_mask = batch[1].to(args.device)\n",
    "    labels = batch[2].to(args.device)\n",
    "    output1 = model1(input_ids, token_type_ids=None, attention_mask=input_mask, labels=labels)\n",
    "    output2 = model2(input_ids, token_type_ids=None, attention_mask=input_mask, labels=labels)\n",
    "    loss1 += output1.loss.item()\n",
    "    loss2 += output2.loss.item()\n",
    "    preds_batch1 = torch.argmax(output1.logits, axis=1)\n",
    "    preds_batch2 = torch.argmax(output2.logits, axis=1)\n",
    "    batch_acc1 = torch.mean((preds_batch1 == labels).float())\n",
    "    batch_acc2 = torch.mean((preds_batch2 == labels).float())\n",
    "    accuracy1.append(batch_acc1)\n",
    "    accuracy2.append(batch_acc2)\n",
    "    true_labels.extend(labels.cpu().numpy())\n",
    "    pred_labels1.extend(preds_batch1.cpu().numpy())\n",
    "    pred_labels2.extend(preds_batch2.cpu().numpy())\n",
    "        \n",
    "        for true_label, pred_label1, pred_label2 , input_id  in zip(labels, preds_batch1, preds_batch2, input_ids):\n",
    "            if true_label != pred_label1 or true_label != pred_label2 :\n",
    "                text = tokenizer.decode(input_id, skip_special_tokens=True)\n",
    "                matching_rows = dataset[dataset['content'].apply(lambda x: Levenshtein.ratio(text, x) >= 0.9)]\n",
    "                if not matching_rows.empty:\n",
    "                    github = matching_rows['github'].iloc[0]\n",
    "                    protocol_id = matching_rows['protocol_id'].iloc[0]\n",
    "\n",
    "                    misclassified_examples.append({'text': text, 'true_label': label_names[true_label.item()], 'predicted1':label_names[pred_label1.item()],'predicted2':label_names[pred_label2.item()], 'github': github, 'protocol_id': protocol_id})\n",
    "                else:\n",
    "                    print(f\"no matching row for text: {text}\")\n",
    "\n",
    "    misclassified_df = pd.DataFrame(misclassified_examples)\n",
    "    misclassified_df.to_csv('data/compare_misclassified_examples.csv', index=False, columns=['text', 'true_label', 'predicted1', 'predicted2', 'github', 'protocol_id'])\n",
    "    \n",
    " # Print misclassified examples\n",
    "    print(\"\\nMisclassified Examples:\")\n",
    "    print(misclassified_examples)\n",
    "\n",
    "    print(\"\\nAccuracy model 1:\", accuracy_score(true_labels, pred_labels1))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, pred_labels1, target_names=list(label_names)))\n",
    "\n",
    "    \n",
    "    print(\"\\nAccuracy model 2:\", accuracy_score(true_labels, pred_labels2))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, pred_labels2, target_names=list(label_names)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swerick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
